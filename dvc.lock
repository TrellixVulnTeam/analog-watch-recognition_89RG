schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 9b3b76e485d7fa9474b516347bdbf12f
      size: 1037833
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      100  --batch-size 16  --seed 42
    deps:
    - path: checkpoints/detector/
      md5: 733a88cd5d39ec938c4c74742abc844d.dir
      size: 422523158
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: e5b158e1ba9fa33d33a5555c4dbb2785
      size: 11006
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: d11a4375eeb63e25ac8aa02c9b9a99d2.dir
      size: 937278
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 8bdcdfe9da4caa1b52ddc8abdca27ef1
      size: 128859
    - path: metrics/detector.json
      md5: 673a5d1509b0cffb311de3cfc49b39fd
      size: 475
    - path: metrics/detector/scalars
      md5: 1ac83b140d1feb195915e9a1b4f4fa48.dir
      size: 34160
      nfiles: 10
    - path: models/detector/
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 85f8a58ad2bdef3ccc7dd4822004fc0f
      size: 5647
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 998cfdfdd145c32f7ba04a6ac11e6237
      size: 133524
    - path: example_predictions/detector/train_1.jpg
      md5: 60dc063fef6b74746e6b8904bec7c926
      size: 107323
    - path: example_predictions/detector/train_2.jpg
      md5: 34e6bc14e0a2d1281a34374155dc4e02
      size: 175824
    - path: example_predictions/detector/train_3.jpg
      md5: 39cc224e037756982b3441a3a6a71e29
      size: 72953
    - path: example_predictions/detector/val_0.jpg
      md5: 5763a2939fc0d3cbfd45647f1f48fab1
      size: 78792
    - path: example_predictions/detector/val_1.jpg
      md5: 4515d81aa03465486e0ad7476c6403bd
      size: 211356
    - path: example_predictions/detector/val_2.jpg
      md5: 768ab403aa794d61f973d45fa860865e
      size: 153971
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 7029288c7ede84abfadbf35535528e27
      size: 2442
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: a3e8d2db168a5401229c632cbf368d2f
      size: 1986
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 7029288c7ede84abfadbf35535528e27
      size: 2442
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: cae0799ca276cec064d06cbee5d9a02d
      size: 1782
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: 1c3ae027505c882e37636a21921d7867
      size: 1469
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: eb9c22f401e52e662cc9020d738478e0
      size: 1059
    - path: metrics/detector/coco_train.json
      md5: 444c12ebf4999121e3d5df5655ec28e4
      size: 286
    - path: metrics/detector/coco_val.json
      md5: 8ee4161e850397181ded4fac31150652
      size: 286
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: a0f2c2d0a2479f3b61ade479bc2a234d.dir
      size: 380658
      nfiles: 38
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 60 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: checkpoints/keypoint/
      md5: 800d7d87380772dcb9fa1010b6f9de07.dir
      size: 84348803
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: 6b11a8ce2f3fb767c97fef80cd0d424b
      size: 6684
    params:
      params.yaml:
        keypoint:
          epochs: 60
          batch-size: 32
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: e309c9e35464291f75fb2a730cb91d99
      size: 66329
    - path: metrics/keypoint.json
      md5: 0878e59197eae345de6a792ed0695fee
      size: 215
    - path: metrics/keypoint/scalars/
      md5: 6ab67e4722058c7f109e9085e1527f6c.dir
      size: 8994
      nfiles: 4
    - path: models/keypoint/
      md5: ab813e19bcc6bb3a47e2696421b9313f.dir
      size: 35988675
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
    - path: models/keypoint/
      md5: ab813e19bcc6bb3a47e2696421b9313f.dir
      size: 35988675
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 3b25b23a8c308884c58b6d5ac4261f0d
      size: 6263
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: c88f9b562a6881c57c36893fefeb045b
      size: 53839
    - path: example_predictions/keypoint/train_1.jpg
      md5: 87782df507220636379cdf79ed0b9f20
      size: 54583
    - path: example_predictions/keypoint/train_2.jpg
      md5: 9bd285d995bcd2fe6ebd7e98dcb2e760
      size: 67126
    - path: example_predictions/keypoint/train_3.jpg
      md5: ff5a460972b36c8b131f9946d3b756e6
      size: 44734
    - path: example_predictions/keypoint/train_4.jpg
      md5: 74424cc21f8979160eaf2901a38c0893
      size: 52295
    - path: example_predictions/keypoint/val_0.jpg
      md5: b8c43f2d8e53a69f467dfbbb567d75c3
      size: 64226
    - path: example_predictions/keypoint/val_1.jpg
      md5: 357330c1bbb170e2a08b2be37685f715
      size: 73869
    - path: example_predictions/keypoint/val_2.jpg
      md5: 70b5a4a1f36037aadc6bee94af6e4e95
      size: 59016
    - path: example_predictions/keypoint/val_3.jpg
      md5: ecb065d6a23e10862a386ea09b0e44b6
      size: 70506
    - path: example_predictions/keypoint/val_4.jpg
      md5: d50cf9c91a05446689bf16c4356ec84f
      size: 61532
    - path: metrics/keypoint/coco_train.json
      md5: 5be6fb20fa614e9f7e6882fc311637b5
      size: 261
    - path: metrics/keypoint/coco_val.json
      md5: bc0f8ca28845720fa6a4d61f1b3f144e
      size: 258
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      60 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: checkpoints/segmentation/
      md5: 356fef3e785c6f0a9ad25ec881438cec.dir
      size: 84321131
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: eb91d62ef3e3dca5a562235c857b30bf
      size: 9490
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 60
          batch-size: 32
          confidence-threshold: 0.5
    outs:
    - path: debug/segmentation/
      md5: 5a909796ecd755473e8af399939ae489.dir
      size: 419750
      nfiles: 2
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 134e8cfec8e0a283df4deb2db84844eb
      size: 58876
    - path: metrics/segmentation.json
      md5: 2f506181f4ce6e82e40fda21221c8697
      size: 215
    - path: metrics/segmentation/scalars/
      md5: ceee6272e0d19d53ac6d8359e20769d7.dir
      size: 9014
      nfiles: 4
    - path: models/segmentation/
      md5: 634aa4d7031932799e3c865bda99a5bb.dir
      size: 35973303
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end-to-end-eval.py
    deps:
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: models/detector
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
    - path: models/keypoint
      md5: ab813e19bcc6bb3a47e2696421b9313f.dir
      size: 35988675
      nfiles: 6
    - path: models/segmentation
      md5: 634aa4d7031932799e3c865bda99a5bb.dir
      size: 35973303
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end-to-end-eval.py
      md5: 9b6aa8409d925be78528458503016657
      size: 7613
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: a1a93d19b380fd068a89df02079e5013
      size: 15780
    - path: metrics/end_2_end_summary.json
      md5: af4aba34cb9a2ee513b9608001f76823
      size: 266
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
    - path: models/segmentation/
      md5: 634aa4d7031932799e3c865bda99a5bb.dir
      size: 35973303
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bb61e11c66fa13cf969f131062185c1e
      size: 3833
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: d13a4b0c652cd39ad11471d919323182
      size: 55717
    - path: example_predictions/segmentation/train_1.jpg
      md5: 4e959554fcb9b5d7a0f6333f401ab46a
      size: 52708
    - path: example_predictions/segmentation/train_2.jpg
      md5: 3f2e922dde3b35faf662e60c1580e224
      size: 60529
    - path: example_predictions/segmentation/train_3.jpg
      md5: b8c8bd9a7effac05324f2e4eeb895064
      size: 47606
    - path: example_predictions/segmentation/train_4.jpg
      md5: 0ce85e186727b0242296aab016b9da2f
      size: 51313
    - path: example_predictions/segmentation/val_0.jpg
      md5: b44c58c8d0f8032224af9727a334a6b1
      size: 54224
    - path: example_predictions/segmentation/val_1.jpg
      md5: ca3591571aebbade55329d460312a42b
      size: 67702
    - path: example_predictions/segmentation/val_2.jpg
      md5: 38fd0efcdfda4b04f272c62992602888
      size: 53373
    - path: example_predictions/segmentation/val_3.jpg
      md5: 8bcbf367f8155d2a53b97e5e5cbfe487
      size: 66361
    - path: example_predictions/segmentation/val_4.jpg
      md5: bbdcdd022d172ea60692c2b187537484
      size: 58019
