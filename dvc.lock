schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: b91771b4afbcc268f6e3b76ff195e06b
      size: 1037986
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 076600f43bf920a12327e4f2a2d54754.dir
      size: 17704892
      nfiles: 37
    - path: datasets/watch-faces-local.json
      md5: c900823f5b63cc402ad8b7aa3aad8707
      size: 1028857
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      60  --batch-size 16  --confidence-threshold 0.5  --seed 42
    deps:
    - path: checkpoints/detector/
      md5: 733a88cd5d39ec938c4c74742abc844d.dir
      size: 422523158
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 076600f43bf920a12327e4f2a2d54754.dir
      size: 17704892
      nfiles: 37
    - path: datasets/watch-faces-local.json
      md5: c900823f5b63cc402ad8b7aa3aad8707
      size: 1028857
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: 44173eb43a48d9990d835c5ed293ce1f
      size: 11019
    params:
      params.yaml:
        detector:
          epochs: 60
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/detector/test-image.jpg
      md5: bd1c3dff2d61b4a3de0787c7423f11c8
      size: 131269
    - path: metrics/detector.json
      md5: 52f9f8b6507b5fe8f6aa4c24bc1f8d92
      size: 480
    - path: metrics/detector/scalars
      md5: 6ff16415f93887a7495c594b802d8a79.dir
      size: 20682
      nfiles: 10
    - path: models/detector/
      md5: cfb3ce9f1a3cb628e3ae52f24bda6ee0.dir
      size: 432222822
      nfiles: 6
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: cfb3ce9f1a3cb628e3ae52f24bda6ee0.dir
      size: 432222822
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 1cf0aeeb84dfb02f2c20a18176c1177c
      size: 5655
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: f986c200aebaa8fcbc47d15c7a4467d6
      size: 110713
    - path: example_predictions/detector/train_1.jpg
      md5: e917d80dc037d0324201d5d235910758
      size: 137416
    - path: example_predictions/detector/train_2.jpg
      md5: b34b12da3fcd5d76f147fb99557a9c9b
      size: 153785
    - path: example_predictions/detector/train_3.jpg
      md5: a5c28ad7ba0ab69194db10d8ba3bffe3
      size: 98498
    - path: example_predictions/detector/val_0.jpg
      md5: 126c716e9fe8f9fa0bc89fb4333ff39d
      size: 141128
    - path: example_predictions/detector/val_1.jpg
      md5: 37ab8115a83ac1aa30a3aed1bfd91783
      size: 201512
    - path: example_predictions/detector/val_2.jpg
      md5: 8c94cd415f1f74545a0428324a531cd7
      size: 112034
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 1d35dea276356bd4c8d3cf27320f4b0f
      size: 2456
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 7356432b6caa7acfcb9b4a9548962078
      size: 1768
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 1d35dea276356bd4c8d3cf27320f4b0f
      size: 2456
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: ef2dcf6ce1bab6ac4aae433b1a196237
      size: 1820
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: 67cdfa6707a9daba8d6791a2eed4c3ea
      size: 1644
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: b625c0a25b4ce632e00a82a7a47f4144
      size: 1187
    - path: metrics/detector/coco_train.json
      md5: d51a9dae78490c21bf15754987693495
      size: 286
    - path: metrics/detector/coco_val.json
      md5: 75b36863aa048befd414ac81db7331d8
      size: 286
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: d7ab119f7b8f853c6e12573cb47e179f.dir
      size: 369200
      nfiles: 47
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 60 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: checkpoints/keypoint/
      md5: 800d7d87380772dcb9fa1010b6f9de07.dir
      size: 84348803
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 076600f43bf920a12327e4f2a2d54754.dir
      size: 17704892
      nfiles: 37
    - path: datasets/watch-faces-local.json
      md5: c900823f5b63cc402ad8b7aa3aad8707
      size: 1028857
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: 16c5e2bb4360922c2ec1397ea8295d8b
      size: 7053
    params:
      params.yaml:
        keypoint:
          epochs: 60
          batch-size: 32
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 993f732d7408069fa9b451269f6b8ddc
      size: 66336
    - path: metrics/keypoint.json
      md5: b261fe4542b832b591e43897c63789ef
      size: 214
    - path: metrics/keypoint/scalars/
      md5: 87b8a7f5d5d7363162432de2540f6896.dir
      size: 9015
      nfiles: 4
    - path: models/keypoint/
      md5: 6381f41f1e5f70130f1dbcfdfd0e93fc.dir
      size: 36542593
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: cfb3ce9f1a3cb628e3ae52f24bda6ee0.dir
      size: 432222822
      nfiles: 6
    - path: models/keypoint/
      md5: 6381f41f1e5f70130f1dbcfdfd0e93fc.dir
      size: 36542593
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 3b25b23a8c308884c58b6d5ac4261f0d
      size: 6263
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: a4bf94ff0a583a36c10bdd346f56c0d9
      size: 44056
    - path: example_predictions/keypoint/train_1.jpg
      md5: 45effd468e16205cb5810f16d6791c24
      size: 43027
    - path: example_predictions/keypoint/train_2.jpg
      md5: fae292e2419c6b0573b98776c43c86b2
      size: 44265
    - path: example_predictions/keypoint/train_3.jpg
      md5: bd2bf8f29d5defbd56a3f606b680d017
      size: 54963
    - path: example_predictions/keypoint/train_4.jpg
      md5: b8b011fd4b80f506ac56d11c8f85fde7
      size: 48659
    - path: example_predictions/keypoint/val_0.jpg
      md5: 4fed3b3862598c07052f73a780c157b2
      size: 30304
    - path: example_predictions/keypoint/val_1.jpg
      md5: c3c9d13c0b9ad2a1b27b145724c331d5
      size: 49264
    - path: example_predictions/keypoint/val_2.jpg
      md5: a59904d54a799571fa9ab715fcd3711e
      size: 64265
    - path: example_predictions/keypoint/val_3.jpg
      md5: 1c41e8e357a1110a013336d5639f9cf3
      size: 46243
    - path: example_predictions/keypoint/val_4.jpg
      md5: ff048920ba32ea4af0046e4d0f93bab8
      size: 39189
    - path: metrics/keypoint/coco_train.json
      md5: 7c4a696e83bffbaa92e17926cb7e875c
      size: 267
    - path: metrics/keypoint/coco_val.json
      md5: 7c57c4a68d5dbd47f40146be8c22b2a5
      size: 247
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      60 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: checkpoints/segmentation/
      md5: 356fef3e785c6f0a9ad25ec881438cec.dir
      size: 84321131
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 076600f43bf920a12327e4f2a2d54754.dir
      size: 17704892
      nfiles: 37
    - path: datasets/watch-faces-local.json
      md5: c900823f5b63cc402ad8b7aa3aad8707
      size: 1028857
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 31611ed07c4dec05d217e9b9c4e2084a
      size: 7436
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 60
          batch-size: 32
          confidence-threshold: 0.5
    outs:
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: ba595a7ae55c273114f220eb6a87d947
      size: 58883
    - path: metrics/segmentation.json
      md5: 5b71b33b1e1c79511e89e5fc4bd720fa
      size: 214
    - path: metrics/segmentation/scalars/
      md5: 306f94c3ef2be96ee6bab9d501da534a.dir
      size: 9017
      nfiles: 4
    - path: models/segmentation/
      md5: 7964f5d267cb6f2e7a5dcbd9a02e38f1.dir
      size: 36527221
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end-to-end-eval.py
    deps:
    - path: datasets/watch-faces-local.json
      md5: c900823f5b63cc402ad8b7aa3aad8707
      size: 1028857
    - path: models/detector
      md5: cfb3ce9f1a3cb628e3ae52f24bda6ee0.dir
      size: 432222822
      nfiles: 6
    - path: models/keypoint
      md5: 6381f41f1e5f70130f1dbcfdfd0e93fc.dir
      size: 36542593
      nfiles: 6
    - path: models/segmentation
      md5: 7964f5d267cb6f2e7a5dcbd9a02e38f1.dir
      size: 36527221
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end-to-end-eval.py
      md5: cb22d328739ec050f1280b2ffecf0a52
      size: 7483
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: b300cb831e3f427190775928b4365c81
      size: 15081
    - path: metrics/end_2_end_summary.json
      md5: 8511e56032c38a59c02e4a5a3be26e56
      size: 268
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: cfb3ce9f1a3cb628e3ae52f24bda6ee0.dir
      size: 432222822
      nfiles: 6
    - path: models/segmentation/
      md5: 7964f5d267cb6f2e7a5dcbd9a02e38f1.dir
      size: 36527221
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: e0967190a45d3e7e9902786aff6caf4e
      size: 4105
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: 9ccd9d6d5feaf64e24b91b096f900def
      size: 42252
    - path: example_predictions/segmentation/train_1.jpg
      md5: 7bd487c620c2288c12d95c308fff6d7f
      size: 43138
    - path: example_predictions/segmentation/train_2.jpg
      md5: 42b02d8dc16016607b5ffdb7815ddece
      size: 42899
    - path: example_predictions/segmentation/train_3.jpg
      md5: 0b8da3d70568524bf018c4be15f55109
      size: 52590
    - path: example_predictions/segmentation/train_4.jpg
      md5: 655c36ca85fccbd9e86361a32eedb59f
      size: 46817
    - path: example_predictions/segmentation/val_0.jpg
      md5: b96110c3651c679f3572c2715f3cacc0
      size: 42996
    - path: example_predictions/segmentation/val_1.jpg
      md5: 1262c6f98600ce6d96d0f2fddfa4a3a4
      size: 43904
    - path: example_predictions/segmentation/val_2.jpg
      md5: 5c27d9e6e976ff2d90e2f0729adfc65c
      size: 43821
    - path: example_predictions/segmentation/val_3.jpg
      md5: 5a0bf82256373c90ed3e9346f9dd7299
      size: 51770
    - path: example_predictions/segmentation/val_4.jpg
      md5: 6999eb6194c4309c53e320baee55cc2a
      size: 46149
