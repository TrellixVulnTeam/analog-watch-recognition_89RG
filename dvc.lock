schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 90e20e9d7b05996a1d315efc0d932dad
      size: 1168571
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      100  --batch-size 16  --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: e5b158e1ba9fa33d33a5555c4dbb2785
      size: 11006
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: f1db36dfa7d13dcfef466237c7f11444.dir
      size: 933292
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 1f80f19cb2ac1c6be1c1d6978007b769
      size: 129792
    - path: metrics/detector.json
      md5: d45243631d1bd9bc17728cc14ab634e1
      size: 474
    - path: metrics/detector/scalars
      md5: a594c76f503bc69e0f5697390d93a365.dir
      size: 34057
      nfiles: 10
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: ca70590c44315e85eacd85b5a9552d59
      size: 4904
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: f41e94b14e4a5826cc6b3d0c368258de
      size: 75174
    - path: example_predictions/detector/train_1.jpg
      md5: 0d81ed87bba8c1a680a13fb71842d748
      size: 105608
    - path: example_predictions/detector/train_2.jpg
      md5: 55d7827d080f1fb693b36a5689a26cfc
      size: 106501
    - path: example_predictions/detector/train_3.jpg
      md5: eb2c8396be7e6471071b4c14235bc54c
      size: 99513
    - path: example_predictions/detector/val_0.jpg
      md5: 79465056152b7871d9735aff89d6f757
      size: 87328
    - path: example_predictions/detector/val_1.jpg
      md5: 2aaca0ccf60ebd52df04e2b0351ac1ee
      size: 124749
    - path: example_predictions/detector/val_2.jpg
      md5: cdbb685b93dc38a25064d70986f31512
      size: 117283
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 73fd20c198ef4b19158b46fa295df506
      size: 2386
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 721accd77832b511c9d448ab5bbdb54d
      size: 2094
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 73fd20c198ef4b19158b46fa295df506
      size: 2386
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: 8ed085102d8cfde0081676db2e269f83
      size: 1646
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: 1171c61e40651ff3b4e8328359ae6375
      size: 1453
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: 6010742813bf9bf4da5fb175d964af31
      size: 1127
    - path: metrics/detector/coco_train.json
      md5: 5356f5fa4ccac78a86a66dd9e8059278
      size: 286
    - path: metrics/detector/coco_val.json
      md5: 0f90d5f6ba56073c21d9ce179c1537b5
      size: 285
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: a0f2c2d0a2479f3b61ade479bc2a234d.dir
      size: 380658
      nfiles: 38
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: e207cb8a105dddf9c60f93b25e87c4a5
      size: 6826
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 7727cfb4fb3ba558506c5827b2eea117
      size: 66363
    - path: metrics/keypoint.json
      md5: 261b7075efcd413d7c458497831388c7
      size: 215
    - path: metrics/keypoint/scalars/
      md5: 07ef9103b4f2a330ed5fa476a6f672fc.dir
      size: 14969
      nfiles: 4
    - path: models/keypoint/
      md5: 4883aa0423b570a75c987fe12917892e.dir
      size: 35988675
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
    - path: models/keypoint/
      md5: ab813e19bcc6bb3a47e2696421b9313f.dir
      size: 35988675
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 3b25b23a8c308884c58b6d5ac4261f0d
      size: 6263
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: c88f9b562a6881c57c36893fefeb045b
      size: 53839
    - path: example_predictions/keypoint/train_1.jpg
      md5: 87782df507220636379cdf79ed0b9f20
      size: 54583
    - path: example_predictions/keypoint/train_2.jpg
      md5: 9bd285d995bcd2fe6ebd7e98dcb2e760
      size: 67126
    - path: example_predictions/keypoint/train_3.jpg
      md5: ff5a460972b36c8b131f9946d3b756e6
      size: 44734
    - path: example_predictions/keypoint/train_4.jpg
      md5: 74424cc21f8979160eaf2901a38c0893
      size: 52295
    - path: example_predictions/keypoint/val_0.jpg
      md5: b8c43f2d8e53a69f467dfbbb567d75c3
      size: 64226
    - path: example_predictions/keypoint/val_1.jpg
      md5: 357330c1bbb170e2a08b2be37685f715
      size: 73869
    - path: example_predictions/keypoint/val_2.jpg
      md5: 70b5a4a1f36037aadc6bee94af6e4e95
      size: 59016
    - path: example_predictions/keypoint/val_3.jpg
      md5: ecb065d6a23e10862a386ea09b0e44b6
      size: 70506
    - path: example_predictions/keypoint/val_4.jpg
      md5: d50cf9c91a05446689bf16c4356ec84f
      size: 61532
    - path: metrics/keypoint/coco_train.json
      md5: 5be6fb20fa614e9f7e6882fc311637b5
      size: 261
    - path: metrics/keypoint/coco_val.json
      md5: bc0f8ca28845720fa6a4d61f1b3f144e
      size: 258
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 4ac5ac8647443147a73877af03908a12
      size: 9632
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
    outs:
    - path: debug/segmentation/
      md5: a94bdd87371d35a697d6a0b90dcad565.dir
      size: 410583
      nfiles: 2
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 9b8d1e5547af6087eebb0090a397ab01
      size: 56009
    - path: metrics/segmentation.json
      md5: 412302d5af89ab0941486f96793a7139
      size: 213
    - path: metrics/segmentation/scalars/
      md5: 7ea4513bb0dca9618b606dfd295bf103.dir
      size: 14955
      nfiles: 4
    - path: models/segmentation/
      md5: 3092355bb88b2e4bdb656c57bd1729dd.dir
      size: 35973303
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end-to-end-eval.py
    deps:
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: models/detector
      md5: ec51668e545c8d4875efb7073d9f9e97.dir
      size: 432253678
      nfiles: 5
    - path: models/keypoint
      md5: ab813e19bcc6bb3a47e2696421b9313f.dir
      size: 35988675
      nfiles: 6
    - path: models/segmentation
      md5: 634aa4d7031932799e3c865bda99a5bb.dir
      size: 35973303
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end-to-end-eval.py
      md5: 9b6aa8409d925be78528458503016657
      size: 7613
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: a1a93d19b380fd068a89df02079e5013
      size: 15780
    - path: metrics/end_2_end_summary.json
      md5: af4aba34cb9a2ee513b9608001f76823
      size: 266
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
    - path: models/segmentation/
      md5: 3092355bb88b2e4bdb656c57bd1729dd.dir
      size: 35973303
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: 5ae4862923f65a0884b2d374b3f406f2
      size: 3317
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: ece59f6f60c1930ffe3c0585b1c7cccf
      size: 56898
    - path: example_predictions/segmentation/train_1.jpg
      md5: acd018f9a5f9a81476603a9f4dee1c08
      size: 80057
    - path: example_predictions/segmentation/train_2.jpg
      md5: 13b7d22146ed2fc78b32fd8635403114
      size: 82091
    - path: example_predictions/segmentation/train_3.jpg
      md5: e7faa536d56032c7222862f85bb7b9de
      size: 73506
    - path: example_predictions/segmentation/train_4.jpg
      md5: b1560363a4d89a054a1395444c352df3
      size: 74553
    - path: example_predictions/segmentation/val_0.jpg
      md5: 08b8fa4093561385210f5100b7c14308
      size: 62517
    - path: example_predictions/segmentation/val_1.jpg
      md5: 26daf0d0e0de4a9f21fb58eaef1b2706
      size: 79942
    - path: example_predictions/segmentation/val_2.jpg
      md5: fd0ce2ac909bde342036eabc2bc01ef6
      size: 62779
    - path: example_predictions/segmentation/val_3.jpg
      md5: 4b38661baf21e4c599ce23136d5d40a5
      size: 77753
    - path: example_predictions/segmentation/val_4.jpg
      md5: 42e91763602ab96dd71fd2e9faa226ec
      size: 68770
