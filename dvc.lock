schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 9b3b76e485d7fa9474b516347bdbf12f
      size: 1037833
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      1  --batch-size 16  --seed 42
    deps:
    - path: checkpoints/detector/
      md5: 262b04cceb42d0e7658bf70da75b501e.dir
      size: 436687933
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: 25da2ec67f2384c30984b463e297c43d
      size: 11026
    params:
      params.yaml:
        detector:
          epochs: 1
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/detector/test-image.jpg
      md5: be59f803021d276f2c1cbc9708a9166e
      size: 151765
    - path: metrics/detector.json
      md5: 79c944b696649389fede14bd927ee6c1
      size: 475
    - path: metrics/detector/scalars
      md5: 0c0e6a7a6508f30305c54321e0446f51.dir
      size: 681
      nfiles: 10
    - path: models/detector/
      md5: 9db5c8beec89b2e8e383741cc9aec8be.dir
      size: 432244890
      nfiles: 6
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: d3eadf6c6862324b19d22da1b4db2514.dir
      size: 432247520
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 1cf0aeeb84dfb02f2c20a18176c1177c
      size: 5655
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 2aeb8ab0da1355058ba4950d964ea2a8
      size: 132784
    - path: example_predictions/detector/train_1.jpg
      md5: d5fce2cdf36d34511da2ad765d8e6c53
      size: 107097
    - path: example_predictions/detector/train_2.jpg
      md5: 06552fcad9dcb02c48bbfd44e66bb16e
      size: 174215
    - path: example_predictions/detector/train_3.jpg
      md5: 6191d23f7290d652ea9f6f210f58985e
      size: 74225
    - path: example_predictions/detector/val_0.jpg
      md5: d47770e32ec15b38303ab48c14281e48
      size: 78816
    - path: example_predictions/detector/val_1.jpg
      md5: 2572f8e52d300960bfadd7ec10195c04
      size: 211466
    - path: example_predictions/detector/val_2.jpg
      md5: d58fbdd8c91f7e8455f0fde27c1e4cca
      size: 152733
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 31bbef968c08f534a6bcf76da4ae29b9
      size: 2389
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 7c511e0370fbd60901de1e3b64ebcc62
      size: 1959
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 31bbef968c08f534a6bcf76da4ae29b9
      size: 2389
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: dee03d8f4cd1f41d41ea9be1b0d724e8
      size: 1815
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: d41cc30d592ef9d1c83f189748509327
      size: 1420
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: 579f8c9b70f58d634c7b861f22f6618f
      size: 1127
    - path: metrics/detector/coco_train.json
      md5: 4d42a2bcf591bfe4639c101e069078f9
      size: 286
    - path: metrics/detector/coco_val.json
      md5: 7914b75c095bc82de9fd1942e88a1825
      size: 286
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: f2211f7fca5dba3946613273efb86d5b.dir
      size: 476471
      nfiles: 53
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 60 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: checkpoints/keypoint/
      md5: 5ae05af000e93f90d4166c3100151e64.dir
      size: 84348803
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: ae76e9de6b3cd7ef488c42fb28629061
      size: 6705
    params:
      params.yaml:
        keypoint:
          epochs: 60
          batch-size: 32
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 532de9f69ea6f750ab54c8ec41de4a5a
      size: 66394
    - path: metrics/keypoint.json
      md5: 7f5215f12428018523045e93c34d9450
      size: 214
    - path: metrics/keypoint/scalars/
      md5: 6bd0921b8fb9ca4cafbb36495c21e891.dir
      size: 9008
      nfiles: 4
    - path: models/keypoint/
      md5: ba63e4469cb99039366e44baf0d6f84a.dir
      size: 36001424
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: d3eadf6c6862324b19d22da1b4db2514.dir
      size: 432247520
      nfiles: 6
    - path: models/keypoint/
      md5: ba63e4469cb99039366e44baf0d6f84a.dir
      size: 36001424
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 3b25b23a8c308884c58b6d5ac4261f0d
      size: 6263
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: 67cc564a510fa4da31fb03e65c2760f7
      size: 53837
    - path: example_predictions/keypoint/train_1.jpg
      md5: ff8e053bf87abb748cc8e59d5a176f6a
      size: 54560
    - path: example_predictions/keypoint/train_2.jpg
      md5: cf6094831fbd1f3432e8c66e97d74107
      size: 67172
    - path: example_predictions/keypoint/train_3.jpg
      md5: 62976dd3a71d056de2e909604adbd6bd
      size: 44724
    - path: example_predictions/keypoint/train_4.jpg
      md5: bc6c4fe8fe9d0ef2c38a3edf5e5788fa
      size: 52309
    - path: example_predictions/keypoint/val_0.jpg
      md5: 9c6a66ea25a0995eccfae1da602a6c26
      size: 64450
    - path: example_predictions/keypoint/val_1.jpg
      md5: 61e1554c4e61ff5b63d93c5fd5f5c628
      size: 73873
    - path: example_predictions/keypoint/val_2.jpg
      md5: 264152d6f138d41a32add12579be072f
      size: 59033
    - path: example_predictions/keypoint/val_3.jpg
      md5: cba0245a35298fac0b3a0f4eb570bdcb
      size: 70420
    - path: example_predictions/keypoint/val_4.jpg
      md5: 3006cad66d9dc12a4f13eae240173431
      size: 61497
    - path: metrics/keypoint/coco_train.json
      md5: 23211642c6778f4f711f6295d5340d14
      size: 259
    - path: metrics/keypoint/coco_val.json
      md5: 1581143091e5396c1f2e699ef2d9432f
      size: 262
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      60 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: checkpoints/segmentation/
      md5: 816b05e29ec1bb6beb1d35c61097fa2e.dir
      size: 84321131
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c517cd143a36c8444e7e19718ab7153c.dir
      size: 94131818
      nfiles: 218
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 41be6df603556b2c4e237afb201ce577
      size: 9559
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 60
          batch-size: 32
          confidence-threshold: 0.5
    outs:
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 9a8b64e7f56802a4d2d9153cf929cccb
      size: 58799
    - path: metrics/segmentation.json
      md5: f3de35b74060c126fa2fb4db41a33b1c
      size: 214
    - path: metrics/segmentation/scalars/
      md5: 474fda6b37204d6979744b0e16c30da2.dir
      size: 9019
      nfiles: 4
    - path: models/segmentation/
      md5: ad7d6cb932a7a49381a61c809b8f555d.dir
      size: 35986052
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end-to-end-eval.py
    deps:
    - path: datasets/watch-faces-local.json
      md5: 19a7a1b6308828fc1238ca0e54237b35
      size: 1030933
    - path: models/detector
      md5: d3eadf6c6862324b19d22da1b4db2514.dir
      size: 432247520
      nfiles: 6
    - path: models/keypoint
      md5: ba63e4469cb99039366e44baf0d6f84a.dir
      size: 36001424
      nfiles: 6
    - path: models/segmentation
      md5: ad7d6cb932a7a49381a61c809b8f555d.dir
      size: 35986052
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end-to-end-eval.py
      md5: cb22d328739ec050f1280b2ffecf0a52
      size: 7483
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: 774944e890befc99d2b4e5b830ce796a
      size: 13993
    - path: metrics/end_2_end_summary.json
      md5: d7d58855ae227fbfe451a0015f422333
      size: 170
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: d3eadf6c6862324b19d22da1b4db2514.dir
      size: 432247520
      nfiles: 6
    - path: models/segmentation/
      md5: ad7d6cb932a7a49381a61c809b8f555d.dir
      size: 35986052
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bb61e11c66fa13cf969f131062185c1e
      size: 3833
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: 433c27a22275051fe9503dafb198aaf1
      size: 55800
    - path: example_predictions/segmentation/train_1.jpg
      md5: 2e3ebab195ded1137e2564e2694084a3
      size: 52667
    - path: example_predictions/segmentation/train_2.jpg
      md5: 8fb0e3b095c29734751a390fe81247dd
      size: 60648
    - path: example_predictions/segmentation/train_3.jpg
      md5: a715a309f1d8d88e0b9a18c650cc8c19
      size: 47641
    - path: example_predictions/segmentation/train_4.jpg
      md5: febdc58988ac9259bcad4bceae302208
      size: 51462
    - path: example_predictions/segmentation/val_0.jpg
      md5: 8efe30cda48fe504a38dea5f43394a64
      size: 54198
    - path: example_predictions/segmentation/val_1.jpg
      md5: f156795b15a26bad62c95de62a98a23d
      size: 67779
    - path: example_predictions/segmentation/val_2.jpg
      md5: 8b03e26fca8ed30b99040ededababfce
      size: 53589
    - path: example_predictions/segmentation/val_3.jpg
      md5: 4007e25879670439fb72a86bd6fccc01
      size: 66337
    - path: example_predictions/segmentation/val_4.jpg
      md5: 55cffa5826c38547a38e9d27115a4fa1
      size: 57973
