schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json
    deps:
    - path: datasets/watch-faces.json
      md5: c70bbbfd4a8de47b9a9fd603c5c79d1b
      size: 661929
    - path: scripts/download-images.py
      md5: 163a2ddbebf57d03fc4ac6640fff005b
      size: 1804
    outs:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 17f79e1cbb37ff869a2b6109fd5ecff8.dir
      size: 79597491
      nfiles: 141
    - path: datasets/val
      md5: 36595d9dbbeadbc1801e2f9062eeac99.dir
      size: 8720873
      nfiles: 15
    - path: datasets/watch-faces-local.json
      md5: 1474f420d322c3c9d92ce1c9b4a6dd4a
      size: 657283
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      50  --batch-size 16  --confidence-threshold 0.5  --seed 42 --fine-tune-from-checkpoint
    deps:
    - path: checkpoints/detector/
      md5: 4f0ef251a21db42f82d745ffc44d4b34.dir
      size: 436687933
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 17f79e1cbb37ff869a2b6109fd5ecff8.dir
      size: 79597491
      nfiles: 141
    - path: datasets/val
      md5: 99f455ab8c8d2db34f9b5c994e17cb00.dir
      size: 6906661
      nfiles: 9
    - path: datasets/watch-faces-local.json
      md5: db7c3dda8302f2f04fc4d627941d0551
      size: 581754
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: 4f2a8f7f6133997316921fba3ea47740
      size: 32743
    params:
      params.yaml:
        detector:
          epochs: 50
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/detector/test-image.jpg
      md5: 7249de1759196ae706070163da7f3928
      size: 128316
    - path: metrics/detector.json
      md5: a434b865503c1c0b52ae2493b96daa63
      size: 133
    - path: metrics/detector/scalars
      md5: 6825b301d4a20982655160be79ae6de4.dir
      size: 3827
      nfiles: 2
    - path: models/detector/
      md5: f70e53057a8ce36d3d5d94674063b006.dir
      size: 155270393
      nfiles: 6
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: f70e53057a8ce36d3d5d94674063b006.dir
      size: 155270393
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 207dcb18332eb320dfd9caded5fa665f
      size: 5874
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 83def3ffc5fdab99428c03fc415e4141
      size: 205109
    - path: example_predictions/detector/train_1.jpg
      md5: 8de6ab1276f7c6064a9879e2e7b7d213
      size: 112090
    - path: example_predictions/detector/train_2.jpg
      md5: 9027e39cbc6e1f5dd7f7d7c4b4157b49
      size: 89286
    - path: example_predictions/detector/train_3.jpg
      md5: 6bd77663ddda0d3ecd5092ed2ca1054c
      size: 136601
    - path: example_predictions/detector/train_4.jpg
      md5: 567c3f46b4d3e6b664e8629dead62fd5
      size: 84809
    - path: example_predictions/detector/val_0.jpg
      md5: 6215a047fd57aec39948c20cae69ac36
      size: 83623
    - path: example_predictions/detector/val_1.jpg
      md5: 08b9379df36b7d93e6911d4af92be58b
      size: 133044
    - path: example_predictions/detector/val_2.jpg
      md5: a97b1c5ad6cb404d6eb11324309b1864
      size: 206006
    - path: example_predictions/detector/val_3.jpg
      md5: 6b492f328fb6fe0604a60b63ea7fa3b0
      size: 112522
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 460dd219f8336a05cfdc4fe4ab966d0a
      size: 1845
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: d3196f21e47a77724bec0b8293e1e81d
      size: 1059
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 285d5dcf4b3d85f6717e53792d44ba30
      size: 1825
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: d3196f21e47a77724bec0b8293e1e81d
      size: 1059
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: b8381158ae22353c1f9a2cc98eaf1d9c
      size: 1154
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: eb9c22f401e52e662cc9020d738478e0
      size: 1059
    - path: metrics/detector/coco_train.json
      md5: 0b369d9437eebf50a053b7e4bcee0e53
      size: 289
    - path: metrics/detector/coco_val.json
      md5: 01dc153b3d61e2a7d032f9eee6c78882
      size: 254
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 97381e37e3e55770f5084d8368158ba6.dir
      size: 175659
      nfiles: 35
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 25 --batch-size 16 --confidence-threshold 0.5 --seed 42 --fine-tune-from-checkpoint
    deps:
    - path: checkpoints/keypoint/
      md5: 93aaf13ff65a6ac56d4a9b0562091545.dir
      size: 84348803
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 17f79e1cbb37ff869a2b6109fd5ecff8.dir
      size: 79597491
      nfiles: 141
    - path: datasets/val
      md5: 99f455ab8c8d2db34f9b5c994e17cb00.dir
      size: 6906661
      nfiles: 9
    - path: datasets/watch-faces-local.json
      md5: db7c3dda8302f2f04fc4d627941d0551
      size: 581754
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: 16c5e2bb4360922c2ec1397ea8295d8b
      size: 7053
    params:
      params.yaml:
        keypoint:
          epochs: 25
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 7ee498ee0f271fc6d63e319d4e3cc4cb
      size: 66347
    - path: metrics/keypoint.json
      md5: 919df3405310d4def0d8f744cac477b6
      size: 215
    - path: metrics/keypoint/scalars/
      md5: db12b50afd43a9f5c9d20643c1145c8c.dir
      size: 3787
      nfiles: 4
    - path: models/keypoint/
      md5: 5b5fd2d01bdfaee39485957b474151e9.dir
      size: 36529126
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: f70e53057a8ce36d3d5d94674063b006.dir
      size: 155270393
      nfiles: 6
    - path: models/keypoint/
      md5: 5b5fd2d01bdfaee39485957b474151e9.dir
      size: 36529126
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 1489e93239ed225a7b1ba65075ef48a2
      size: 6107
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: e76163d88024a8e7772fcb0070a46b80
      size: 73572
    - path: example_predictions/keypoint/train_1.jpg
      md5: 14ca1d24b41933fca528abe8556fb117
      size: 51105
    - path: example_predictions/keypoint/train_2.jpg
      md5: 80ce0e75fe204693e32a155278651020
      size: 59948
    - path: example_predictions/keypoint/train_3.jpg
      md5: 119256a527e09ad34d8634990982cb04
      size: 27448
    - path: example_predictions/keypoint/train_4.jpg
      md5: 623b5ae543195a5f0dfc0785d8bfe87e
      size: 38961
    - path: example_predictions/keypoint/val_0.jpg
      md5: 90a28bc572cd293d530f17822da6074c
      size: 57141
    - path: example_predictions/keypoint/val_1.jpg
      md5: 798ac8851f7c4b38c7d5964c6e515e98
      size: 61497
    - path: example_predictions/keypoint/val_2.jpg
      md5: c489efbaefbca8506673d2545f54dfd6
      size: 70437
    - path: example_predictions/keypoint/val_3.jpg
      md5: da01a48d3b96a73f6d717a678b0e8773
      size: 59026
    - path: example_predictions/keypoint/val_4.jpg
      md5: 9374cde95ca004384c9e89db492576f3
      size: 73933
    - path: metrics/keypoint/coco_train.json
      md5: 45fbc6bded3fc1ba41d35261ca30046b
      size: 266
    - path: metrics/keypoint/coco_val.json
      md5: b68dd9db38e95d6eece116208a9d44b1
      size: 214
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      25 --batch-size 16 --confidence-threshold 0.5 --seed 42 --fine-tune-from-checkpoint
    deps:
    - path: checkpoints/segmentation/
      md5: f69ac8b89feb20dbd86a7e770e9fe38e.dir
      size: 84321131
      nfiles: 3
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 17f79e1cbb37ff869a2b6109fd5ecff8.dir
      size: 79597491
      nfiles: 141
    - path: datasets/val
      md5: 99f455ab8c8d2db34f9b5c994e17cb00.dir
      size: 6906661
      nfiles: 9
    - path: datasets/watch-faces-local.json
      md5: db7c3dda8302f2f04fc4d627941d0551
      size: 581754
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 31611ed07c4dec05d217e9b9c4e2084a
      size: 7436
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 25
          batch-size: 16
          confidence-threshold: 0.5
    outs:
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 81dde74b42325668d5115fbc01c24b1a
      size: 59003
    - path: metrics/segmentation.json
      md5: cbbd708da28a8e7c4996832c9c32ccd7
      size: 215
    - path: metrics/segmentation/scalars/
      md5: 5020bdcce1c55e6e1c8765064254e7cc.dir
      size: 3817
      nfiles: 4
    - path: models/segmentation/
      md5: 921e131b10d7c9ea78819be446f0125d.dir
      size: 36513754
      nfiles: 5
