{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.callbacks import AverageModelCheckpoint\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tflite_model_maker import object_detector\n",
    "from pathlib import Path\n",
    "\n",
    "voc_train_ds_path = Path(\"./data/annotations-train/watch-faces-train-PascalVOC-export\")\n",
    "voc_val_ds_path = Path(\n",
    "    \"./data/annotations-validation/watch-faces-validation-PascalVOC-export\")\n",
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    str(voc_train_ds_path / 'JPEGImages'),\n",
    "    str(voc_train_ds_path / 'Annotations'),\n",
    "    label_map={1: 'watch-face'},\n",
    "        max_num_images=2\n",
    ")\n",
    "validation_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    str(voc_val_ds_path / 'JPEGImages'),\n",
    "    str(voc_val_ds_path / 'Annotations'),\n",
    "    label_map={1: 'watch-face'},\n",
    "                        max_num_images=1\n",
    "\n",
    "\n",
    ")\n",
    "len(train_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds =  train_data.gen_dataset(spec)\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "for x in ds.take(1).as_numpy_iterator():\n",
    "    # print(x)\n",
    "    img = x[0][0]\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    # Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow_examples.lite.model_maker.third_party.efficientdet.keras.train_lib import EfficientDetNetTrain\n",
    "from tensorflow_examples.lite.model_maker.core.task.model_spec.object_detector_spec import EfficientDetModelSpec\n",
    "from tensorflow_examples.lite.model_maker.third_party.efficientdet.keras import efficientdet_keras\n",
    "import tensorflow as tf\n",
    "from tflite_model_maker import model_spec\n",
    "spec = model_spec.get('efficientdet_lite0')\n",
    "dict(spec.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spec.config.update({'num_classes':1, 'weight_decay': 0, 'image_size': (224, 224)})\n",
    "# temporary disable augmentations\n",
    "spec.config.update({'jitter_max': 1.0, 'jitter_min': 1.0 })\n",
    "class MyModel(EfficientDetNetTrain):\n",
    "\n",
    "    @classmethod\n",
    "    def conv2d_layer(cls):\n",
    "        data_format = 'channels_last'\n",
    "        config_separable_conv = True\n",
    "        return efficientdet_keras.ClassNet.conv2d_layer(\n",
    "            config_separable_conv, data_format)\n",
    "    def _backbone_base_model(self):\n",
    "        backbone = tf.keras.applications.ResNet50(\n",
    "        include_top=False, input_shape=[None, None, 3]\n",
    "        )\n",
    "        c3_output, c4_output, c5_output = [\n",
    "            backbone.get_layer(layer_name).output\n",
    "            for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n",
    "        ]\n",
    "        return tf.keras.Model(\n",
    "            inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n",
    "        )\n",
    "\n",
    "\n",
    "        return tf.keras.models.Sequential(\n",
    "                [\n",
    "                    self.conv2d_layer()(kernel_size=3, filters=self.num_filters, activation=tf.nn.relu6, padding='same'),\n",
    "                    tf.keras.layers.MaxPool2D(),\n",
    "                    self.conv2d_layer()(kernel_size=3, filters=self.num_filters*2, activation=tf.nn.relu6,padding='same'),\n",
    "                    tf.keras.layers.MaxPool2D(),\n",
    "                    self.conv2d_layer()(kernel_size=3, filters=self.num_filters*2, activation=tf.nn.relu6,padding='same'),\n",
    "                    tf.keras.layers.MaxPool2D(),\n",
    "                 ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__(config=spec.config)\n",
    "        data_format = 'channels_last'\n",
    "        config_separable_conv = True\n",
    "        self.num_filters = 256\n",
    "        config_aspect_ratios = spec.config.aspect_ratios\n",
    "        config_num_scales = spec.config.num_scales\n",
    "        config_num_classes = spec.config.num_classes\n",
    "        num_anchors = len(config_aspect_ratios) * config_num_scales\n",
    "\n",
    "        self.base_model = self._backbone_base_model()\n",
    "\n",
    "        self.pre_classes = self.conv2d_layer()(kernel_size=3, filters=self.num_filters, activation=tf.nn.relu6,padding='same')\n",
    "        self.pre_box = self.conv2d_layer()(kernel_size=3, filters=self.num_filters, activation=tf.nn.relu6,padding='same')\n",
    "\n",
    "\n",
    "        self.classes = efficientdet_keras.ClassNet.classes_layer(\n",
    "            self.conv2d_layer(),\n",
    "            config_num_classes,\n",
    "            num_anchors,\n",
    "            name='class_net/class-predict',\n",
    "        )\n",
    "\n",
    "        self.boxes = efficientdet_keras.BoxNet.boxes_layer(\n",
    "            config_separable_conv,\n",
    "            num_anchors,\n",
    "            data_format,\n",
    "            name='box_net/box-predict')\n",
    "    # log_dir = os.path.join(self.config.model_dir, 'train_images')\n",
    "    # self.summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # cls_outputs, box_outputs = self.base_model(inputs, training=training)\n",
    "        outputs = self.base_model(inputs, training=training)\n",
    "\n",
    "        # cls_outputs = [self.classes(self.pre_classes(outputs))]\n",
    "        # box_outputs = [self.boxes(self.pre_box(outputs))]\n",
    "        config_max_level = 7\n",
    "        self_config_min_level = 3\n",
    "        cls_outputs = [None for i in range(2)]\n",
    "        box_outputs = [None for i in range(2)]\n",
    "        for i in range(2):\n",
    "            cls_outputs[i] = self.classes(outputs[i])\n",
    "            box_outputs[i] = self.boxes(outputs[i])\n",
    "            # outputs[i] = self.classes(outputs[i])\n",
    "            # outputs[i] = self.boxes(outputs[i])\n",
    "        return cls_outputs, box_outputs\n",
    "\n",
    "class CustomSpec(EfficientDetModelSpec):\n",
    "    def create_model(self):\n",
    "        return MyModel()\n",
    "# TODO\n",
    "# override tensorflow_examples.lite.model_maker.core.task.model_spec.object_detector_spec.EfficientDetModelSpec.create_model\n",
    "# to return model with the same outputs as tensorflow_examples.lite.model_maker.third_party.efficientdet.keras.train_lib.EfficientDetNetTrainHub\n",
    "# if that won't work you'll have to rewrite a half of tflite model maker in kers to run this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = MyModel()\n",
    "m.build((None, 224, 224, 3))\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = object_detector.create(\n",
    "    train_data,\n",
    "    model_spec=CustomSpec('efficientdet-lite0', uri=\"\"),\n",
    "    batch_size=1,\n",
    "    train_whole_model=True,\n",
    "    # validation_data=validation_data,\n",
    "        epochs=100,\n",
    "        # do_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history['cls_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history['box_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img = np.array(Image.new('RGB', (320,320)))\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "img = img[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO convert model to saved_model first, then to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "converter.target_spec.supported_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile('custom.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'name': 'efficientdet-lite0',\n",
    "    'act_type': 'relu6',\n",
    "    'image_size': (320, 320),\n",
    "    'target_size': None,\n",
    "    'input_rand_hflip': True,\n",
    "    'jitter_min': 0.1,\n",
    "    'jitter_max': 2.0,\n",
    "    'autoaugment_policy': None,\n",
    "    'grid_mask': False,\n",
    "    'sample_image': None,\n",
    "    'map_freq': 5,\n",
    "    'num_classes': 2,\n",
    "    'seg_num_classes': 3,\n",
    "    'heads': ['object_detection'],\n",
    "    'skip_crowd_during_training': True,\n",
    "    'label_map': {1: 'watch-face'},\n",
    "    'max_instances_per_image': 100,\n",
    "    'regenerate_source_id': False,\n",
    "    'min_level': 3,\n",
    "    'max_level': 7,\n",
    "    'num_scales': 3,\n",
    "    'aspect_ratios': [1.0, 2.0, 0.5],\n",
    "    'anchor_scale': 3.0,\n",
    "    'is_training_bn': True,\n",
    "    'momentum': 0.9,\n",
    "    'optimizer': 'sgd',\n",
    "    'learning_rate': 0.08,\n",
    "    'lr_warmup_init': 0.008,\n",
    "    'lr_warmup_epoch': 1.0,\n",
    "    'first_lr_drop_epoch': 200.0,\n",
    "    'second_lr_drop_epoch': 250.0,\n",
    "    'poly_lr_power': 0.9,\n",
    "    'clip_gradients_norm': 10.0,\n",
    "    'num_epochs': 1,\n",
    "    'data_format': 'channels_last',\n",
    "    'mean_rgb': 127.0,\n",
    "    'stddev_rgb': 128.0,\n",
    "    'scale_range': False,\n",
    "    'label_smoothing': 0.0,\n",
    "    'alpha': 0.25,\n",
    "    'gamma': 1.5,\n",
    "    'delta': 0.1,\n",
    "    'box_loss_weight': 50.0,\n",
    "    'iou_loss_type': None,\n",
    "    'iou_loss_weight': 1.0,\n",
    "    'weight_decay': 4e-05,\n",
    "    'strategy': None,\n",
    "    'mixed_precision': False,\n",
    "    'loss_scale': None,\n",
    "    'model_optimizations': {},\n",
    "    'box_class_repeats': 3,\n",
    "    'fpn_cell_repeats': 3,\n",
    "    'fpn_num_filters': 64,\n",
    "    'separable_conv': True,\n",
    "    'apply_bn_for_resampling': True,\n",
    "    'conv_after_downsample': False,\n",
    "    'conv_bn_act_pattern': False,\n",
    "    'drop_remainder': True,\n",
    "    'nms_configs': {\n",
    "        'method': 'gaussian', 'iou_thresh': None, 'score_thresh': 0.0, 'sigma': None,\n",
    "        'pyfunc': False, 'max_nms_inputs': 0, 'max_output_size': 100\n",
    "    },\n",
    "    'tflite_max_detections': 25,\n",
    "    'fpn_name': None,\n",
    "    'fpn_weight_method': 'sum',\n",
    "    'fpn_config': None,\n",
    "    'survival_prob': None,\n",
    "    'img_summary_steps': None,\n",
    "    'lr_decay_method': 'cosine',\n",
    "    'moving_average_decay': 0,\n",
    "    'ckpt_var_scope': None,\n",
    "    'skip_mismatch': True,\n",
    "    'backbone_name': 'efficientnet-lite0',\n",
    "    'backbone_config': None,\n",
    "    'var_freeze_expr': None,\n",
    "    'use_keras_model': True,\n",
    "    'dataset_type': None,\n",
    "    'positives_momentum': None,\n",
    "    'grad_checkpoint': False,\n",
    "    'verbose': 0,\n",
    "    'save_freq': 'epoch',\n",
    "    'profile': False,\n",
    "    'model_name': 'efficientdet-lite0',\n",
    "    'steps_per_execution': 1,\n",
    "    'model_dir': '/var/folders/ym/8q_z70bx4hb86r1g8_5_98kw0000gn/T/tmpp34ys9s7',\n",
    "    'batch_size': 8,\n",
    "    'tf_random_seed': 111111,\n",
    "    'debug': False\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch)",
   "language": "python",
   "name": "tf-watch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
