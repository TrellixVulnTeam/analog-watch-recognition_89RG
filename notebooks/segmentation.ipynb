{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from watch_recognition.reports import run_on_image_debug\n",
    "from watch_recognition.datasets import view_image\n",
    "from watch_recognition.models import get_unet_model, IouLoss2\n",
    "import segmentation_models as sm\n",
    "%matplotlib inline\n",
    "\n",
    "ROOT_DIR = Path(\"../download_data/\")\n",
    "SAVE_DIR = Path(\"..\")\n",
    "EPOCHS = 100\n",
    "image_size = (96, 96)\n",
    "mask_size = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.data_preprocessing import load_binary_masks_from_coco_dataset\n",
    "\n",
    "\n",
    "\n",
    "X, y, _ = load_binary_masks_from_coco_dataset(\n",
    "    str(ROOT_DIR / \"segmentation/train/result.json\"),\n",
    "    image_size=image_size,\n",
    ")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_val, y_val, _ = load_binary_masks_from_coco_dataset(\n",
    "    str(ROOT_DIR / \"segmentation/validation/result.json\"),\n",
    "    image_size=image_size,\n",
    ")\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((X, y)).shuffle(8*32).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_train = get_watch_keypoints_dataset(X, y, augment=False, image_size=image_size,\n",
    "#                                             mask_size=mask_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# view_image(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_val = get_watch_keypoints_dataset(X_val, y_val, augment=False, image_size=image_size, shuffle=False,\n",
    "#                                             mask_size=mask_size)\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# view_image(dataset_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(dataset_val.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = get_unet_model(\n",
    "    unet_output_layer=None,\n",
    "    image_size=image_size,\n",
    "    n_outputs=1,\n",
    "    output_activation='sigmoid',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = sm.losses.JaccardLoss() + sm.losses.BinaryCELoss()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "TYPE = \"segmentation\"\n",
    "MODEL_NAME = f\"efficientnetb0-unet-sigmoid-{image_size[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from watch_recognition.reports import visualize_high_loss_examples\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[sm.metrics.iou_score, sm.metrics.f1_score]\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "logdir = SAVE_DIR / f\"tensorboard_logs/{TYPE}/{MODEL_NAME}/run_{start.timestamp()}\"\n",
    "print(logdir)\n",
    "file_writer_distance_metrics_train = tf.summary.create_file_writer(str(logdir) + \"/train\")\n",
    "file_writer_distance_metrics_validation = tf.summary.create_file_writer(\n",
    "    str(logdir) + \"/validation\"\n",
    ")\n",
    "\n",
    "model_path = SAVE_DIR / f\"models/{TYPE}/{MODEL_NAME}/run_{start.timestamp()}\"\n",
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=EPOCHS*2,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=logdir,\n",
    "            update_freq=\"epoch\",\n",
    "        ),\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "                on_epoch_end=partial(\n",
    "                    visualize_high_loss_examples,\n",
    "                    dataset=dataset_train,\n",
    "                    loss=loss,\n",
    "                    file_writer=file_writer_distance_metrics_train,\n",
    "                    model=model,\n",
    "                    every_n_epoch=5,\n",
    "                )\n",
    "            ),\n",
    "            tf.keras.callbacks.LambdaCallback(\n",
    "                on_epoch_end=partial(\n",
    "                    visualize_high_loss_examples,\n",
    "                    dataset=dataset_val,\n",
    "                    loss=loss,\n",
    "                    file_writer=file_writer_distance_metrics_validation,\n",
    "                    model=model,\n",
    "                )\n",
    "            ),\n",
    "        # tf.keras.callbacks.ModelCheckpoint(\n",
    "        #     filepath=model_path,\n",
    "        #     save_weights_only=False,\n",
    "        #     monitor=\"val_loss\",\n",
    "        #     save_best_only=True,\n",
    "        # ),\n",
    "    ],\n",
    ")\n",
    "elapsed = (datetime.now() - start).seconds\n",
    "print(\n",
    "    f\"total training time: {elapsed / 60} minutes, average: {elapsed / 60 / EPOCHS} minutes/epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_y = next(iter(dataset_train))\n",
    "train_X, train_y = train_X.numpy(), train_y.numpy()\n",
    "\n",
    "run_on_image_debug(model, train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for image in X_val[10:20]:\n",
    "    run_on_image_debug(model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(model_path)\n",
    "loaded_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "\n",
    "for image in X[10:20]:\n",
    "    run_on_image_debug(loaded_model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for image in X_val[10:20]:\n",
    "    run_on_image_debug(loaded_model, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
