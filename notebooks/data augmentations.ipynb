{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from watch_recognition.data_preprocessing import load_keypoints_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.data_preprocessing import load_keypoints_data_2\n",
    "\n",
    "image_size = (224, 224)\n",
    "X, y = load_keypoints_data_2(\n",
    "    Path(\"../download_data/keypoints/validation\"),\n",
    "    mask_size=(14,14),\n",
    "    extent=(3,3)\n",
    ")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, masks, img_size):\n",
    "    # cast and normalize image\n",
    "    # image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # # apply simple augmentations\n",
    "    # image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.resize(image, [img_size, img_size])\n",
    "    return image, masks\n",
    "\n",
    "\n",
    "ds_tf = dataset.map(partial(process_image, img_size=120),\n",
    "                    num_parallel_calls=AUTOTUNE).batch(30).prefetch(AUTOTUNE)\n",
    "ds_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(ds):\n",
    "    # entry = next(iter(ds)) # extract 1 batch from the dataset\n",
    "    image, mask = next(iter(ds))\n",
    "    image = image.numpy()\n",
    "    mask = mask.numpy()\n",
    "\n",
    "    #     fig = plt.figure(figsize=(22, 22))\n",
    "    fig, axarr = plt.subplots(5, 5, figsize=(22, 22))\n",
    "    for i in range(5):\n",
    "        ax = axarr[i]\n",
    "        print(image[i].max())\n",
    "        img = image[i]\n",
    "        ax[0].imshow(img.astype('uint8'))\n",
    "        ax[0].set_xticks([])\n",
    "        ax[0].set_yticks([])\n",
    "        ax[0].set_title(\"Image\")\n",
    "        for j, tag in enumerate([\"Center\", \"Top\", \"Hour\", \"Minute\"]):\n",
    "            ax_idx = j + 1\n",
    "            ax[ax_idx].imshow(mask[i, :, :, j].astype('uint8'))\n",
    "            ax[ax_idx].set_xticks([])\n",
    "            ax[ax_idx].set_yticks([])\n",
    "            ax[ax_idx].set_title(f\"Point: {tag}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(ds_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast,\n",
    "    HorizontalFlip,\n",
    "    Rotate\n",
    ")\n",
    "from albumentations import RandomBrightnessContrast\n",
    "import random\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomSizedCrop(min_max_height=(50, 101), height=224, width=224, p=0.5),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, p=0.5)\n",
    "    ], p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    # A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.GridDistortion(p=0.5),\n",
    "    ], p=0.8)\n",
    "    ],\n",
    "    additional_targets={\n",
    "        'mask0': 'mask',\n",
    "        'mask1': 'mask',\n",
    "        'mask2': 'mask',\n",
    "        'mask3': 'mask',\n",
    "    })\n",
    "\n",
    "random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.augmentations import process_data\n",
    "\n",
    "ds_alb = dataset.map(partial(process_data, mask_size=(14, 14), image_size=(224, 224)),\n",
    "                     num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "ds_alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.augmentations import set_shapes\n",
    "\n",
    "ds_alb = ds_alb.map(\n",
    "    partial(set_shapes, img_shape=(224, 224, 3), masks_shape=(14,14, 4)),\n",
    "    num_parallel_calls=AUTOTUNE).batch(32).prefetch(AUTOTUNE)\n",
    "ds_alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(ds_alb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(ds_alb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
