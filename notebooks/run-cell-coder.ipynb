{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from watch_recognition.reports import run_on_image_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.reports import calculate_distances_between_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_path = '../cloud_train/local-training-output/heatmap-regression_098DB017/models/keypoint/efficientnetb0-unet-96-hands/run_1636479122.611962/'\n",
    "model_path = '../cloud_train/local-training-output/heatmap-regression_3E56883D/models/keypoint/efficientnetb0-unet-96-hands-dl-bce/run_1636825952.284192/'\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "image_size=loaded_model.inputs[0].shape[1:3]\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for path in [\n",
    "    Path(\"../example_data/Zrzut ekranu 2021-08-25 o 22.24.14.jpg\"),\n",
    "    Path(\"../example_data/Zrzut ekranu 2021-08-25 o 22.24.24.jpg\"),\n",
    "    Path(\"../example_data/test-image-2.jpg\"),\n",
    "]:\n",
    "    test_image = tf.keras.preprocessing.image.load_img(\n",
    "\n",
    "        path, \"rgb\", target_size=image_size, interpolation=\"bicubic\",        \n",
    "    )\n",
    "    test_image_np = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "\n",
    "    run_on_image_debug(loaded_model, test_image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.data_preprocessing import load_keypoints_data_as_kp\n",
    "ROOT_DIR = \"..\"\n",
    "X, y, filenames = load_keypoints_data_as_kp(\n",
    "    str(Path(\"%s/download_data/keypoints/validation\" % ROOT_DIR)), autorotate=True,  image_size=image_size,skip_examples_without_all_keypoints=True,\n",
    ")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.models import *\n",
    "from watch_recognition.targets_encoding import *\n",
    "from watch_recognition.datasets import get_watch_keypoints_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = IouLoss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_watch_keypoints_dataset(X, y, augment=False, image_size=image_size, shuffle=False,\n",
    "                                            mask_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.datasets import  view_image\n",
    "view_image(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.as_numpy_iterator()\n",
    "images = []\n",
    "losses = []\n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in iterator:\n",
    "    X_batch, y_batch = batch\n",
    "    y_pred = loaded_model.predict(X_batch)\n",
    "    for target, pred in zip(y_batch, y_pred):\n",
    "        value = loss(target, pred).numpy()\n",
    "        losses.append(value)\n",
    "    images.append(X_batch)\n",
    "    predictions.append(y_pred)\n",
    "    targets.append(y_batch)\n",
    "images = np.concatenate(images, axis=0)\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "targets = np.concatenate(targets, axis=0)\n",
    "losses = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_examples = np.argsort(losses)[::-1][5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(losses, bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[worst_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.argsort(losses)[::-1][5:10]:\n",
    "    print(losses[idx], filenames[idx])\n",
    "    image = X[idx].astype('uint8')\n",
    "    colored_mask = (targets[idx] * 255).astype('uint8')\n",
    "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
    "    plt.imshow(overlay)\n",
    "    plt.show()\n",
    "    run_on_image_debug(loaded_model, image)\n",
    "    diff = np.abs(targets[idx] - predictions[idx])\n",
    "    plt.imshow(diff)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.datasets import get_watch_keypoints_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = get_watch_keypoints_dataset(\n",
    "        X,\n",
    "        y,\n",
    "        augment=False,\n",
    "        image_size=X.shape[1:3],\n",
    "        mask_size=X.shape[1:3],\n",
    "    ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.datasets import view_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_image(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.models import IouLoss2\n",
    "loss = IouLoss2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = [batch[1].numpy() for batch in dataset_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target = np.concatenate([batch[0].numpy() for batch in dataset_val],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a.shape for a in y_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.concatenate(y_target, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_loss = loss(pred, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "for a, b in zip(pred, targets):\n",
    "    loss_values.append(loss(a,b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(np.array(loss_values))[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_target[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(targets[6], pred[6]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.reports import _visualize_high_loss_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = _visualize_high_loss_examples(dataset_val, loss, loaded_model)\n",
    "plt.imshow(img.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(np.expand_dims(test_image_np, axis=0))\n",
    "hands = pred[0,:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watch_recognition.data_preprocessing import load_keypoints_data_as_kp\n",
    "ROOT_DIR = \"..\"\n",
    "X, y, filenames = load_keypoints_data_as_kp(\n",
    "    str(Path(\"%s/download_data/keypoints/train\" % ROOT_DIR)), autorotate=True,  image_size=image_size,\n",
    ")\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predicted.npz', 'wb') as f:\n",
    "    np.savez(f, X=X, predicted=predicted, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    center_distances,\n",
    "    top_distances,\n",
    "    hour_distances,\n",
    "    minute_distances,\n",
    ") = calculate_distances_between_points(X, predicted, y)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"center_distances\": center_distances,\n",
    "        \"hour_distances\": hour_distances,\n",
    "        \"minute_distances\": minute_distances,\n",
    "        \"top_distances\": top_distances,\n",
    "        \"filename\": filenames,\n",
    "    }\n",
    ")\n",
    "df[\"mean_distances\"] = df.mean(axis=1).values\n",
    "print(df.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from watch_recognition.targets_encoding import convert_mask_outputs_to_keypoints\n",
    "\n",
    "for i, data in df.sort_values(\"mean_distances\", ascending=False).head(5).iterrows():\n",
    "    scale_factor = X.shape[1] / predicted.shape[1]\n",
    "    print(f\"example {filenames[i]}\")\n",
    "    print(data)\n",
    "    with Image.open(Path(\"%s/download_data/keypoints/train\" % ROOT_DIR) / filenames[i]) as img:\n",
    "        print(f\"Original resolution: {img.size}\")\n",
    "\n",
    "    center_hat, top_hat, hour_hat, minute_hat  = convert_mask_outputs_to_keypoints(\n",
    "        predicted[i]\n",
    "    )\n",
    "    center_hat, top_hat, hour_hat, minute_hat = [\n",
    "        np.array(p.as_coordinates_tuple).astype(float)\n",
    "        for p in (center_hat, top_hat, hour_hat, minute_hat)\n",
    "    ]\n",
    "    center_hat = center_hat * scale_factor\n",
    "    top_hat = top_hat * scale_factor\n",
    "    hour_hat = hour_hat * scale_factor\n",
    "    minute_hat = minute_hat * scale_factor\n",
    "    predicted_points = np.stack(\n",
    "        [\n",
    "            center_hat,\n",
    "            top_hat,\n",
    "            hour_hat,\n",
    "            minute_hat,\n",
    "        ]\n",
    "    )\n",
    "   \n",
    "    rounded_predicted_points = np.round(predicted_points)\n",
    "    print(\"targets|predictions\")\n",
    "    print(np.hstack((y[i][:, :2], rounded_predicted_points)))\n",
    "    markers = ['.', '^', '*', 's']\n",
    "    names = ['center', 'top', 'hour', 'minute']\n",
    "    for point, marker, name in zip(predicted_points, markers, names):\n",
    "        plt.scatter(*point, marker=marker, color='red', label=f\"{name}-pred\")\n",
    "    for point, marker, name in zip(y[i][:, :2], markers, names):\n",
    "        plt.scatter(*point, marker=marker, color='green', label=f\"{name}-labeled\")\n",
    "\n",
    "    plt.imshow(X[i])\n",
    "    ax = plt.gca()\n",
    "    # https://stackoverflow.com/a/4701285/8814045\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "\n",
    "    # Put a legend below current axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "    plt.show()\n",
    "    run_on_image_debug(loaded_model, X[i])\n",
    "    print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"..\"\n",
    "X, y, filenames = load_keypoints_data_as_kp(\n",
    "    str(Path(\"%s/download_data/keypoints/validation\" % ROOT_DIR)), autorotate=True,  image_size=image_size,\n",
    ")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    center_distances,\n",
    "    top_distances,\n",
    "    hour_distances,\n",
    "    minute_distances,\n",
    ") = calculate_distances_between_points(X, predicted, y)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"center_distances\": center_distances,\n",
    "        \"hour_distances\": hour_distances,\n",
    "        \"minute_distances\": minute_distances,\n",
    "        \"top_distances\": top_distances,\n",
    "        \"filename\": filenames,\n",
    "    }\n",
    ")\n",
    "df[\"mean_distances\"] = df.mean(axis=1).values\n",
    "print(df.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
