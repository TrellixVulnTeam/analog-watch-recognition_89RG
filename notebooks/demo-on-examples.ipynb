{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.predictors import TFLiteDetector\n",
    "from watch_recognition.predictors import KPPredictor\n",
    "from watch_recognition.predictors import HandPredictor\n",
    "from watch_recognition.predictors import RotationPredictor\n",
    "keypoint_model = '../cloud_train/local-training-output/heatmap-regression_098DB017/models/keypoint/efficientnetb0-unet-96-hands/run_1636479122.611962/'\n",
    "sm_model_path = \"../models/effnet-b3-FPN-(160, 160)-1040-tversky/6602EDDE\"\n",
    "\n",
    "hand_predictor = HandPredictor(sm_model_path)\n",
    "kp_predictor = KPPredictor(keypoint_model)\n",
    "rp = RotationPredictor(\"./models/angle-classifier/efficientnetb0-8/run_1635014448.999021/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "detector = TFLiteDetector(\"./models/detection/efficientdet_lite0/run_1631453124.255371/model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "examples_dir = Path(\"../example_data\")\n",
    "example_images = list(examples_dir.glob(\"IMG*\"))  + list(examples_dir.glob(\"Zrzut*\"))\n",
    "example_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "from watch_recognition.models import points_to_time\n",
    "renders = []\n",
    "for img_path in tqdm(example_images):\n",
    "    with Image.open(img_path) as pil_img:\n",
    "        frame = np.array(pil_img)\n",
    "        bboxes = detector.predict(pil_img)\n",
    "        new_results = []\n",
    "        for box in bboxes:\n",
    "            pred_center, pred_top = kp_predictor.predict_from_image_and_bbox(pil_img, box, rotation_predictor=rp)\n",
    "            frame = pred_center.draw_marker(frame, thickness=2)\n",
    "            frame = pred_top.draw_marker(frame, thickness=2)\n",
    "            minute_and_hour, other = hand_predictor.predict_from_image_and_bbox(pil_img, box, pred_center, debug=False)\n",
    "            if minute_and_hour:\n",
    "                pred_minute, pred_hour = minute_and_hour\n",
    "                minute_kp = dataclasses.replace(pred_minute.end, name=\"Minute\")\n",
    "                hour_kp = dataclasses.replace(pred_hour.end, name=\"Hour\")\n",
    "                read_hour, read_minute = points_to_time(\n",
    "                    pred_center, hour_kp, minute_kp, pred_top\n",
    "                )\n",
    "                frame = pred_minute.draw(frame, thickness=3)\n",
    "                frame = pred_minute.end.draw_marker(frame, thickness=2)\n",
    "                frame = pred_hour.draw(frame, thickness=7, color=(255, 128,0))\n",
    "                frame = pred_hour.end.draw_marker(frame, thickness=2)\n",
    "\n",
    "                time = f\"{read_hour:02.0f}:{read_minute:02.0f}\"\n",
    "                new_results.append(dataclasses.replace(box, name=time))\n",
    "            else:\n",
    "                new_results.append(dataclasses.replace(box, name=\"???\"))\n",
    "\n",
    "            for line in other:\n",
    "                frame = line.draw(frame, thickness=2, color=(255, 0, 0))\n",
    "        for box in new_results:\n",
    "            frame = box.draw(frame)\n",
    "        renders.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for source, render in zip(example_images, renders):\n",
    "    img = Image.fromarray(render)\n",
    "    save_path = source.parent / (source.stem + \"_render.jpg\")\n",
    "    img.save(save_path)\n",
    "    img .thumbnail((1000, 1000))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
