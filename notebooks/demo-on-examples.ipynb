{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "def download_and_uzip_model(url, save_dir=\"/tmp/\"):\n",
    "    save_dir = Path(save_dir)\n",
    "    name = url.split('/')[-1]\n",
    "    save_file = (save_dir / name)\n",
    "    if not save_file.exists():\n",
    "        print(f\"downloading {name}\")\n",
    "        with requests.get(url,stream=True) as response:\n",
    "            with save_file.open('wb') as f:\n",
    "                f.write(response.content)\n",
    "    extract_dir = save_dir / save_file.stem\n",
    "    with tarfile.open(save_file) as tar:\n",
    "        print(f\"extracting {name}\")\n",
    "        tar.extractall(extract_dir)\n",
    "\n",
    "    return extract_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.predictors import TFLiteDetector\n",
    "from watch_recognition.predictors import KPPredictor\n",
    "from watch_recognition.predictors import HandPredictor\n",
    "from watch_recognition.predictors import RotationPredictor\n",
    "hand_predictor = HandPredictor(download_and_uzip_model(url = \"https://storage.googleapis.com/akuc-ml-public/models/effnet-b3-FPN-160-tversky-hands.tar.gz\"))\n",
    "kp_predictor = KPPredictor(download_and_uzip_model(url=\"https://storage.googleapis.com/akuc-ml-public/models/efficientnetb0-unet-96-hands-kp.tar.gz\"))\n",
    "rp = RotationPredictor(download_and_uzip_model(url = \"https://storage.googleapis.com/akuc-ml-public/models/efficientnetb0-8-angle.tar.gz\"))\n",
    "detector = TFLiteDetector(download_and_uzip_model(url=\"https://storage.googleapis.com/akuc-ml-public/models/efficientdet_lite0-detector.tar.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "examples_dir = Path(\"../example_data\")\n",
    "example_images = list(examples_dir.glob(\"IMG*\"))  + list(examples_dir.glob(\"Zrzut*\"))\n",
    "example_images = [img for img in example_images if \"render\" not in img.name]\n",
    "example_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "from watch_recognition.models import points_to_time\n",
    "renders = []\n",
    "for img_path in tqdm(example_images):\n",
    "    with Image.open(img_path) as pil_img:\n",
    "        frame = np.array(pil_img)\n",
    "        bboxes = detector.predict(pil_img)\n",
    "        new_results = []\n",
    "        for box in bboxes:\n",
    "            pred_center, pred_top = kp_predictor.predict_from_image_and_bbox(pil_img, box, rotation_predictor=rp)\n",
    "            frame = pred_center.draw_marker(frame, thickness=2)\n",
    "            frame = pred_top.draw_marker(frame, thickness=2)\n",
    "            minute_and_hour, other = hand_predictor.predict_from_image_and_bbox(pil_img, box, pred_center, debug=False)\n",
    "            if minute_and_hour:\n",
    "                pred_minute, pred_hour = minute_and_hour\n",
    "                minute_kp = dataclasses.replace(pred_minute.end, name=\"Minute\")\n",
    "                hour_kp = dataclasses.replace(pred_hour.end, name=\"Hour\")\n",
    "                read_hour, read_minute = points_to_time(\n",
    "                    pred_center, hour_kp, minute_kp, pred_top\n",
    "                )\n",
    "                frame = pred_minute.draw(frame, thickness=3)\n",
    "                frame = pred_minute.end.draw_marker(frame, thickness=2)\n",
    "                frame = pred_hour.draw(frame, thickness=7, color=(255, 128,0))\n",
    "                frame = pred_hour.end.draw_marker(frame, thickness=2)\n",
    "\n",
    "                time = f\"{read_hour:02.0f}:{read_minute:02.0f}\"\n",
    "                new_results.append(dataclasses.replace(box, name=time))\n",
    "            else:\n",
    "                new_results.append(dataclasses.replace(box, name=\"???\"))\n",
    "\n",
    "            for line in other:\n",
    "                frame = line.draw(frame, thickness=2, color=(255, 0, 0))\n",
    "        for box in new_results:\n",
    "            frame = box.draw(frame)\n",
    "        renders.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for source, render in zip(example_images, renders):\n",
    "    img = Image.fromarray(render)\n",
    "    save_path = source.parent / (source.stem + \"_render.jpg\")\n",
    "    img.save(save_path)\n",
    "    img .thumbnail((1000, 1000))\n",
    "    display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
