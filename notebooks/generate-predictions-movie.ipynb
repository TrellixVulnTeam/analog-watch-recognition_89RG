{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.predictors import TFLiteDetector\n",
    "from watch_recognition.predictors import KPPredictor\n",
    "from watch_recognition.predictors import HandPredictor\n",
    "from watch_recognition.predictors import RotationPredictor\n",
    "keypoint_model = '../cloud_train/local-training-output/heatmap-regression_098DB017/models/keypoint/efficientnetb0-unet-96-hands/run_1636479122.611962/'\n",
    "sm_model_path = \"../models/effnet-b3-FPN-(160, 160)-935-weighted-jl/F661D8C2\"\n",
    "\n",
    "hand_predictor = HandPredictor(sm_model_path)\n",
    "kp_predictor = KPPredictor(keypoint_model)\n",
    "rp = RotationPredictor(\"./models/angle-classifier/efficientnetb0-8/run_1635014448.999021/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "detector = TFLiteDetector(\"./models/detection/efficientdet_lite0/run_1633100188.371347/model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import dataclasses\n",
    "from watch_recognition.models import points_to_time\n",
    "\n",
    "file = Path('../IMG_1200_720p.mov')\n",
    "assert file.exists()\n",
    "cap = cv2.VideoCapture(str(file))\n",
    "\n",
    "# Read until video is completed\n",
    "print((int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "out = cv2.VideoWriter(\n",
    "    \"outpy_13.mp4\",\n",
    "    cv2.VideoWriter_fourcc('A','V','C','1'),\n",
    "    cap.get(cv2.CAP_PROP_FPS) - 10,\n",
    "    (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))),\n",
    ")\n",
    "crop_padding = (int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) - int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))//2\n",
    "print(crop_padding)\n",
    "use_angle_model = False\n",
    "frame_id = 0\n",
    "with tqdm(total=393) as pbar:\n",
    "    while cap.isOpened():\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = frame[crop_padding:-crop_padding, :]\n",
    "            new_results = []\n",
    "            with Image.fromarray(frame) as pil_img:\n",
    "                try:\n",
    "                    bboxes = detector.predict(pil_img)\n",
    "                    for box in bboxes:\n",
    "                        pred_center, pred_top = kp_predictor.predict_from_image_and_bbox(pil_img, box, rotation_predictor=rp)\n",
    "                        frame = pred_center.draw_marker(frame, thickness=2)\n",
    "                        frame = pred_top.draw_marker(frame, thickness=2)\n",
    "                        minute_and_hour, other = hand_predictor.predict_from_image_and_bbox(pil_img, box, pred_center)\n",
    "                        if minute_and_hour:\n",
    "                            pred_minute, pred_hour = minute_and_hour\n",
    "                            read_hour, read_minute = points_to_time(\n",
    "                                pred_center, pred_hour.end, pred_minute.end, pred_top\n",
    "                            )\n",
    "                            frame = pred_minute.draw(frame, thickness=3)\n",
    "                            frame = pred_minute.end.draw_marker(frame, thickness=2)\n",
    "                            frame = pred_hour.draw(frame, thickness=5)\n",
    "                            frame = pred_hour.end.draw_marker(frame, thickness=2)\n",
    "\n",
    "                            time = f\"{read_hour:.0f}:{read_minute:.0f}\"\n",
    "                            new_results.append(dataclasses.replace(box, name=time))\n",
    "                        else:\n",
    "                            new_results.append(dataclasses.replace(box, name=\"???\"))\n",
    "\n",
    "                        for line in other:\n",
    "                            frame = line.draw(frame, thickness=1, color=(255, 0, 0))\n",
    "                except Exception as e:\n",
    "                    print(e, frame_id)\n",
    "                    raise e\n",
    "            for box in new_results:\n",
    "                frame = box.draw(frame)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            out.write(frame)\n",
    "        # Break the loop\n",
    "        else:\n",
    "            break\n",
    "        frame_id += 1\n",
    "        pbar.update(1)\n",
    "        # if frame_id > 2:\n",
    "        #     break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "frame_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
