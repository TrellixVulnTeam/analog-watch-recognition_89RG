{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "np.random.seed(37)\n",
    "rn.seed(1254)\n",
    "tf.random.set_seed(89)\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from watch_recognition.models import build_backbone\n",
    "from watch_recognition.reports import log_distances, run_on_image_debug, generate_report_for_keypoints\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "EPOCHS = 300\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(*image_size, 3),\n",
    "        include_top=False,\n",
    "    )\n",
    "for layer in base_model.layers:\n",
    "    if 'project_conv' in layer.name:\n",
    "        print(layer.name, layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model = build_backbone(image_size)\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "inputs = tf.keras.Input(shape=(*image_size, 3), )\n",
    "x = base_model(inputs)\n",
    "# x = tf.keras.layers.Conv2D(\n",
    "#     filters=128, kernel_size=3, strides=1, padding=\"same\", activation='relu'\n",
    "# )(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2, strides=1,padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=3, strides=1, padding=\"same\", activation='relu'\n",
    ")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2, strides=1,padding='same')(x)\n",
    "output = tf.keras.layers.Conv2D(\n",
    "    filters=4, kernel_size=1, strides=1, padding=\"same\", activation='sigmoid'\n",
    ")(x)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=inputs, outputs=output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.output.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.data_preprocessing import load_keypoints_data_2\n",
    "\n",
    "X, y = load_keypoints_data_2(\n",
    "    Path(\"../download_data/keypoints/train\"),\n",
    "    mask_size=(14,14),\n",
    "    extent=(3,3)\n",
    ")\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.augmentations import aug_fn, process_data, set_shapes\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "ds_alb = dataset.map(partial(process_data, mask_size=(14, 14), image_size=(224, 224)),\n",
    "                     num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "ds_alb = ds_alb.map(\n",
    "    partial(set_shapes, img_shape=(224, 224, 3), masks_shape=(14,14, 4)),\n",
    "    num_parallel_calls=AUTOTUNE).batch(32).prefetch(AUTOTUNE)\n",
    "ds_alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_val, y_val = load_keypoints_data_2(\n",
    "    Path(\"../download_data/keypoints/validation\"),\n",
    "    mask_size=(14,14),\n",
    "    extent=(3,3)\n",
    ")\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from watch_recognition.models import custom_focal_loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=1e-8)\n",
    "loss = custom_focal_loss\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "start = datetime.now()\n",
    "TYPE='keypoint'\n",
    "MODEL_NAME='efficientnetb0'\n",
    "logdir = f\"tensorboard_logs/{TYPE}/{MODEL_NAME}/run_{start.timestamp()}\"\n",
    "print(logdir)\n",
    "file_writer_distance_metrics_train = tf.summary.create_file_writer(logdir + \"/train\")\n",
    "file_writer_distance_metrics_validation = tf.summary.create_file_writer(logdir + \"/validation\")\n",
    "\n",
    "model_path = f'models/{TYPE}/{MODEL_NAME}/run_{start.timestamp()}.h5'\n",
    "model.fit(\n",
    "    ds_alb,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=logdir,\n",
    "            update_freq=\"epoch\",\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=model_path,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss', factor=0.8,\n",
    "                              patience=20, min_lr=1e-6),\n",
    "        # tf.keras.callbacks.EarlyStopping(\n",
    "        #     monitor=\"val_loss\",\n",
    "        #     restore_best_weights=True,\n",
    "        #     patience=15,\n",
    "        # ),\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=partial(log_distances, X=X, y=y,\n",
    "                                 file_writer=file_writer_distance_metrics_train, model=model)),\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=partial(log_distances, X=X_val, y=y_val,\n",
    "                                 file_writer=file_writer_distance_metrics_validation, model=model)),\n",
    "    ]\n",
    ")\n",
    "elapsed = (datetime.now() - start).seconds\n",
    "print(f\"total training time: {elapsed / 60} minutes, average: {elapsed/60/EPOCHS} minutes/epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_on_image_debug(model, X[0], y[0], show_grid=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = Path(\"../example_data/Zrzut ekranu 2021-08-25 o 22.24.14.png\")\n",
    "test_image = tf.keras.preprocessing.image.load_img(\n",
    "    path, \"rgb\", target_size=image_size, interpolation=\"bicubic\",\n",
    ")\n",
    "test_image_np = tf.keras.preprocessing.image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_on_image_debug(model, test_image_np, show_grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_report_for_keypoints(model, X, y, show_top_n_errors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_report_for_keypoints(model, X_val, y_val, show_top_n_errors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"./models/keypoint/efficientnetb0/run_1629928881.918389.h5\"\n",
    "loaded_model = tf.keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for path in [\n",
    "    Path(\"../example_data/Zrzut ekranu 2021-08-25 o 22.24.14.png\"),\n",
    "    Path(\"../example_data/Zrzut ekranu 2021-08-25 o 22.24.24.png\"),\n",
    "    Path(\"../example_data/test-image-2.jpg\"),\n",
    "]:\n",
    "    test_image = tf.keras.preprocessing.image.load_img(\n",
    "        path, \"rgb\", target_size=image_size, interpolation=\"bicubic\",\n",
    "    )\n",
    "    test_image_np = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "\n",
    "    run_on_image_debug(loaded_model, test_image_np, show_grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_report_for_keypoints(loaded_model, X, y, show_top_n_errors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generate_report_for_keypoints(loaded_model, X_val, y_val, show_top_n_errors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
