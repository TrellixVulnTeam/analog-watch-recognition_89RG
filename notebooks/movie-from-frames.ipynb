{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from PIL.Image import BICUBIC\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from watch_recognition.utilities import predictions_to_polygon\n",
    "from watch_recognition.targets_encoding import select_hand_points_with_line_fits\n",
    "from skimage.color import label2rgb\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
    "from functools import lru_cache\n",
    "from PIL import ImageOps\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import erosion, skeletonize, thin\n",
    "from skimage.measure import regionprops\n",
    "from skimage import measure\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from matplotlib import cm\n",
    "from skimage.filters import gaussian\n",
    "from watch_recognition.utilities import Point, Line\n",
    "from IPython.display import display\n",
    "from PIL import ImageOps\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from watch_recognition.utilities import mean_line, minmax_line\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "from skimage.morphology import skeletonize\n",
    "from watch_recognition.targets_encoding import convert_mask_outputs_to_keypoints\n",
    "from skimage.transform import rescale\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft2, fftshift\n",
    "from skimage.draw import line as draw_line\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.data import astronaut\n",
    "from watch_recognition.data_preprocessing import load_image\n",
    "from skimage.measure import label\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keypoint_model = '../cloud_train/local-training-output/heatmap-regression_098DB017/models/keypoint/efficientnetb0-unet-96-hands/run_1636479122.611962/'\n",
    "# keypoint_model = '../models/run_1635107772.736066'\n",
    "# keypoint_model = '../models/keypoint/efficientnetb0-unet-sigmoid-128/run_1635363092.476276'\n",
    "sm_model_path = \"../cloud_train/local-training-output/segmentation/segmentation_48D99B6B/models/segmentation/efficientnetb0-unet-(96, 96)-391-aug/export/\"\n",
    "sm_model = tf.keras.models.load_model(sm_model_path, compile=False)\n",
    "kp_model = tf.keras.models.load_model(keypoint_model, compile=False)\n",
    "image_size = tuple(sm_model.inputs[0].shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_kp_on_image(original_image, point: Point):\n",
    "    # Plot the detection results on the input image\n",
    "    original_image_np = original_image.astype(np.uint8)\n",
    "\n",
    "    x, y = point.as_coordinates_tuple\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "\n",
    "    # Draw the bounding box and label on the image\n",
    "    cv2.drawMarker(original_image_np, (x, y), (255, 0, 0), cv2.MARKER_CROSS,\n",
    "                   thickness=1, markerSize=3)\n",
    "\n",
    "    # Return the final image\n",
    "    original_uint8 = original_image_np.astype(np.uint8)\n",
    "    return original_uint8\n",
    "\n",
    "\n",
    "def plot_line_on_image(original_image, line: Line):\n",
    "    original_image_np = original_image.astype(np.uint8)\n",
    "\n",
    "    start = line.start.as_coordinates_tuple\n",
    "    end = line.end.as_coordinates_tuple\n",
    "    start = tuple(map(int, start))\n",
    "    end = tuple(map(int, end))\n",
    "    cv2.line(original_image_np, start, end, (0, 255, 0))\n",
    "    # Return the final image\n",
    "    original_uint8 = original_image_np.astype(np.uint8)\n",
    "    return original_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file = sorted(Path(\"./frames/\").glob(\"*_0.jpg\"))[0]\n",
    "with Image.open(file) as crop:\n",
    "    display(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "crop_rotated_resized_np = ImageOps.pad(\n",
    "    crop,\n",
    "    image_size, BICUBIC\n",
    ")\n",
    "frame = np.array(crop_rotated_resized_np).copy()\n",
    "# keypoints\n",
    "image_np = np.expand_dims(crop_rotated_resized_np, 0)\n",
    "predicted = sm_model.predict(\n",
    "    image_np\n",
    ")[0]\n",
    "\n",
    "\n",
    "predicted_kp = kp_model.predict(image_np)[0]\n",
    "center = convert_mask_outputs_to_keypoints(predicted_kp,\n",
    "                                            decode_hands_from_lines=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "image = predicted.copy()\n",
    "\n",
    "image = rescale(image, 5, anti_aliasing=True, )\n",
    "image = image[:,:,0].squeeze()\n",
    "image = (image > 0.1).astype(int)\n",
    "print(image.shape)\n",
    "\n",
    "image_f = np.abs(fftshift(fft2(image)))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
    "ax = axes.ravel()\n",
    "ax[0].set_title(\"Original image\")\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[1].set_title(\"Original FFT (frequency)\")\n",
    "ax[1].imshow(np.log(image_f), cmap='magma')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from watch_recognition.utilities import Line, mean_line\n",
    "def kmeans_cluster_lines(lines: List[Line], n_clusters=3):\n",
    "    xs = []\n",
    "    n_features = 0\n",
    "    for line in lines:\n",
    "\n",
    "        x = np.hstack((line.unit_vector, line.center.as_array))\n",
    "        x = np.append(x,line.slope)\n",
    "        n_features = len(x)\n",
    "        xs.append(x)\n",
    "\n",
    "    X = np.array(xs)\n",
    "    X = X.reshape(-1, n_features)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    clusters = defaultdict(list)\n",
    "    for i, label in enumerate(kmeans.labels_):\n",
    "        l = lines[i]\n",
    "        clusters[label].append(l)\n",
    "\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def probabilistic_hugh_transform(image, center, debug=False):\n",
    "    image = image.squeeze()\n",
    "    thresholded_image = (image > 0.1).astype('bool')\n",
    "\n",
    "    label_image = label(thresholded_image)\n",
    "\n",
    "    image_label_overlay = label2rgb(label_image, image=thresholded_image, bg_label=0)\n",
    "    # select the largest object to filter out small false positives\n",
    "    region = sorted(regionprops(label_image), key=lambda r: r.area, reverse=True)[0]\n",
    "    region_image = label_image == region.label\n",
    "    # image = canny(image)\n",
    "    line_length =int( np.sqrt(region.bbox_area) / 3)\n",
    "\n",
    "\n",
    "    lines = probabilistic_hough_line(region_image, line_length=line_length, threshold=1, seed=42, line_gap=10)\n",
    "\n",
    "    new_lines = []\n",
    "    for start, end in lines:\n",
    "        start_p = Point(*start)\n",
    "        end_p = Point(*end)\n",
    "        origin = Point(0, 0)\n",
    "        if end_p.distance(origin) < start_p.distance(origin):\n",
    "            end_p, start_p = start_p, end_p\n",
    "        l = Line(start_p, end_p)\n",
    "        new_lines.append(l)\n",
    "    lines = new_lines\n",
    "    if not lines:\n",
    "        raise ValueError\n",
    "    clustered_lines = kmeans_cluster_lines(lines)\n",
    "    # clustered_lines = []\n",
    "    if debug:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax = axes.ravel()\n",
    "        for l in lines:\n",
    "            l.plot(ax=ax[0])\n",
    "        ax[0].imshow(image, cmap=cm.gray)\n",
    "        ax[0].set_title('Input image')\n",
    "        center.plot(ax[0])\n",
    "        idx_to_color = {0: 'g', 1:'r', 2:'m'}\n",
    "        for i, lines in clustered_lines.items():\n",
    "            l = mean_line(lines)\n",
    "            l.plot(ax[1], lw=5, color=idx_to_color[i])\n",
    "            for line in lines:\n",
    "                line.plot(ax[1], color=idx_to_color[i])\n",
    "\n",
    "        ax[1].imshow(image, cmap=cm.gray)\n",
    "        ax[1].set_xlim((0, image.shape[1]))\n",
    "        ax[1].set_ylim((image.shape[0], 0))\n",
    "        ax[1].set_title('Probabilistic Hough')\n",
    "        center.plot(ax[1])\n",
    "\n",
    "        for a in ax:\n",
    "            a.set_axis_off()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return lines\n",
    "\n",
    "probabilistic_hugh_transform(predicted, center, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_img = load_image('../example_data/Zrzut ekranu 2021-08-25 o 22.24.14.jpg', image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted = sm_model.predict(np.expand_dims(test_img, 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "poly = predictions_to_polygon(predicted, debug=True, approximation_tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_points_from_predictions(predicted_img, center: Point, debug=False):\n",
    "    predicted_img = predicted_img.squeeze()\n",
    "    thresholded_image = (predicted_img > 0.1)\n",
    "    label_image = label(thresholded_image)\n",
    "\n",
    "    image_label_overlay = label2rgb(label_image, image=thresholded_image, bg_label=0)\n",
    "    # select the largest object to filter out small false positives\n",
    "    region = sorted(regionprops(label_image), key=lambda r: r.area, reverse=True)[0]\n",
    "    region_image = label_image == region.label\n",
    "\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red', linewidth=2)\n",
    "\n",
    "    coords = corner_peaks(corner_harris(region_image), min_distance=3, threshold_rel=0.1)\n",
    "\n",
    "    # select only convex cornes (their position is the True pixels)\n",
    "    coords = np.array([coord for coord in coords if np.all(region_image[coord[0], coord[1]])])\n",
    "\n",
    "    hand_points_proposals = [Point(coord[1], coord[0]) for coord in coords]\n",
    "\n",
    "    hands = select_hand_points_with_line_fits(center, hand_points_proposals, max_distance=10)\n",
    "\n",
    "    if debug:\n",
    "        plt.imshow(predicted_img, cmap=cm.gray)\n",
    "        plt.show()\n",
    "        plt.imshow(thresholded_image, cmap=cm.gray)\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        center.plot(ax)\n",
    "        ax.imshow(image_label_overlay)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        center.plot(ax)\n",
    "        ax.imshow(region_image, cmap=cm.gray_r)\n",
    "        ax.add_patch(rect)\n",
    "        for hand in hand_points_proposals:\n",
    "            hand.plot(ax=ax, color='r', marker='x', size=50)\n",
    "\n",
    "        for hand in hands:\n",
    "            hand.plot(ax=ax, color='g', marker='x', size=50)\n",
    "    return hands\n",
    "\n",
    "extract_points_from_predictions(predicted, center=center, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def hugh_transform(predicted_img, center: Point, debug):\n",
    "    predicted_img = predicted_img.squeeze()\n",
    "\n",
    "    blurred_image = gaussian(predicted_img)\n",
    "\n",
    "    thresholded_image = (predicted_img > 0.1)\n",
    "    blurred_thresholded_image = (blurred_image > 0.1)\n",
    "\n",
    "    skeletonized_image = skeletonize(predicted_img)\n",
    "\n",
    "    center_image = np.zeros_like(predicted_img)\n",
    "    int_center = tuple(map(int, map(np.round, center.as_coordinates_tuple)))\n",
    "    center_image[int_center[1], int_center[0]] = 1\n",
    "\n",
    "\n",
    "\n",
    "    tested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n",
    "\n",
    "    h1, theta1, d1 = hough_line(thresholded_image, theta=tested_angles, )\n",
    "    h2, theta2, d2 = hough_line(blurred_thresholded_image, theta=tested_angles, )\n",
    "    h3, theta3, d3 = hough_line(skeletonized_image, theta=tested_angles, )\n",
    "\n",
    "    h = h1+h2+h3\n",
    "    theta = theta1#+theta2\n",
    "    d = d1#+d2\n",
    "\n",
    "\n",
    "    angle_step = 0.5 * np.diff(theta).mean()\n",
    "    d_step = 0.5 * np.diff(d).mean()\n",
    "    bounds = [np.rad2deg(theta[0] - angle_step),\n",
    "              np.rad2deg(theta[-1] + angle_step),\n",
    "              d[-1] + d_step, d[0] - d_step]\n",
    "\n",
    "    kernel = np.array([\n",
    "        [1,2,1],\n",
    "        [2,4,2],\n",
    "        [1,2,1],\n",
    "    ]   )\n",
    "\n",
    "    h = scipy.signal.convolve2d(h, kernel, mode='same')\n",
    "    h = h/16\n",
    "    m = h.max()\n",
    "    h = h/m\n",
    "    feature_map = np.log(1 + h)\n",
    "    feature_map_1 = feature_map > 0.2\n",
    "\n",
    "    # feature_map_3 = feature_map > 0.5\n",
    "    feature_map = feature_map_1\n",
    "\n",
    "\n",
    "\n",
    "    # feature_map = np.where(feature_map> 0.5, feature_map, np.zeros_like(feature_map))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "\n",
    "    label_image = label(feature_map_1)\n",
    "    image_label_overlay = label2rgb(label_image, image=feature_map_1, bg_label=0)\n",
    "    # select the largest object to filter out small false positives\n",
    "    ax[1].imshow(image_label_overlay)\n",
    "    regions = regionprops(label_image)\n",
    "    regions = [region for region in regions if region.area > 50]\n",
    "    for region in regions:\n",
    "        y0, x0 = region.centroid\n",
    "        ax[1].scatter(x0, y0)\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red', linewidth=2)\n",
    "\n",
    "        # print(region.minor_axis_length)\n",
    "\n",
    "\n",
    "        ax[1].add_patch(rect)\n",
    "        angle = theta[int(x0)]\n",
    "        dist = d[int(y0)]\n",
    "        (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "        # print(x0, y0)\n",
    "        # print((np.exp(feature_map_1[int(x0), int(y0)])-1)*m)\n",
    "        # print()\n",
    "        slope = np.tan(angle + np.pi / 2)\n",
    "        ax[2].axline((x0, y0), slope=slope)\n",
    "\n",
    "\n",
    "\n",
    "    ax[0].imshow(thresholded_image, cmap=cm.gray_r)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].set_axis_off()\n",
    "    # ax[0].scatter(*int_center)\n",
    "\n",
    "\n",
    "    # ax[1].imshow(feature_map, extent=bounds, cmap=cm.gray_r, aspect=1 / 1.5)\n",
    "    ax[1].set_title('Hough transform')\n",
    "    ax[1].set_xlabel('Angles (degrees)')\n",
    "    ax[1].set_ylabel('Distance (pixels)')\n",
    "    ax[1].axis('image')\n",
    "\n",
    "    ax[2].imshow(thresholded_image, cmap=cm.gray_r)\n",
    "    ax[2].set_ylim((thresholded_image.shape[0], 0))\n",
    "    ax[2].set_axis_off()\n",
    "    ax[2].set_title('Detected lines')\n",
    "    # ax[2].scatter(*int_center)\n",
    "\n",
    "    peaks = hough_line_peaks(h, theta, d, num_peaks=3)\n",
    "    peaks = list(zip(*peaks))\n",
    "    peaks = sorted(peaks, key=lambda x: x[0], reverse=True)[:3] # select top 3 lines by peak intensity\n",
    "\n",
    "    # for intensity, angle, dist in peaks:\n",
    "    #     print(intensity)\n",
    "    #     ax[1].scatter(np.rad2deg(angle), dist, marker='x')\n",
    "    #     (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "    #     ax[2].axline((x0, y0), slope=np.tan(angle + np.pi / 2))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    # X, Y = np.meshgrid(theta, d)\n",
    "    # print(theta)\n",
    "    # feature_map = feature_map[1:-1, 1:-1]\n",
    "    # bottom = np.zeros_like(feature_map)\n",
    "    # width = angle_step\n",
    "    # depth = d_step\n",
    "    # top =feature_map\n",
    "    # ax.bar3d(X.ravel(), Y.ravel(), bottom.ravel(), width, depth, top.ravel(), shade=True)\n",
    "\n",
    "    # surf = ax.plot_surface(X, Y, feature_map, cmap=cm.coolwarm,\n",
    "    #                    linewidth=0, antialiased=True,)\n",
    "    # # Add a color bar which maps values to colors.\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hugh_transform(predicted, center=center, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "from skimage.transform import probabilistic_hough_line\n",
    "\n",
    "from watch_recognition.utilities import mean_line, minmax_line\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "def cluster_lines(line_proposals: List[Line]):\n",
    "\n",
    "    line_clusters = defaultdict(list)\n",
    "    for i, line in enumerate(line_proposals):\n",
    "        for line_id, lines in line_clusters.items():\n",
    "            mean_slope = np.mean([l.unit_vector for l in lines], axis=0)\n",
    "            if mean_slope @ line.unit_vector.T > 0.99:\n",
    "                line_clusters[line_id].append(line)\n",
    "                break\n",
    "        else:\n",
    "            line_clusters[i].append(line)\n",
    "    # print(f\"n clusters {len(line_clusters)}\")\n",
    "    num_lines = 0\n",
    "    for i, lines in line_clusters.items():\n",
    "        num_lines += len(lines)\n",
    "\n",
    "    assert num_lines == len(line_proposals)\n",
    "    ok_lines = []\n",
    "    for i, lines in line_clusters.items():\n",
    "        if len(lines) == 1:\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            line = mean_line(lines)\n",
    "            # print('ok line', len(lines), line.length)\n",
    "\n",
    "            ok_lines.append(line)\n",
    "    return ok_lines\n",
    "\n",
    "def probabilistic_hugh_transform(image, center, debug=False):\n",
    "    image = image.squeeze()\n",
    "    image = (image > 0).astype('bool') * 255\n",
    "\n",
    "    edges = canny(image, 2, 1, 25)\n",
    "    lines = probabilistic_hough_line(image, threshold=10, line_length=12,\n",
    "                                     line_gap=3, seed=42)\n",
    "    new_lines = []\n",
    "    for start, end in lines:\n",
    "        start_p = Point(*start)\n",
    "        end_p = Point(*end)\n",
    "        origin = Point(0,0)\n",
    "        if end_p.distance(origin) < start_p.distance(origin):\n",
    "            start_p, end_p = end_p, start_p\n",
    "        new_lines.append(Line(start_p, end_p))\n",
    "    lines = new_lines\n",
    "\n",
    "    clustered_lines = cluster_lines(lines)\n",
    "    if debug:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax = axes.ravel()\n",
    "        for l in clustered_lines:\n",
    "            l.plot(ax=ax[0])\n",
    "        ax[0].imshow(image, cmap=cm.gray)\n",
    "        ax[0].set_title('Input image')\n",
    "        center.plot(ax[0])\n",
    "\n",
    "        ax[1].imshow(edges * 0)\n",
    "        for line in lines:\n",
    "            line.plot(ax[1])\n",
    "        ax[1].set_xlim((0, image.shape[1]))\n",
    "        ax[1].set_ylim((image.shape[0], 0))\n",
    "        ax[1].set_title('Probabilistic Hough')\n",
    "        center.plot(ax[1])\n",
    "\n",
    "        for a in ax:\n",
    "            a.set_axis_off()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return clustered_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter(\n",
    "    \"watch-face-1.mov\",\n",
    "    cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"),\n",
    "    10,\n",
    "    (image_size[0], image_size[1]),\n",
    ")\n",
    "use_angle_model = False\n",
    "\n",
    "for i, file in enumerate(tqdm(sorted(Path(\"./frames/\").glob(\"*_0.jpg\")))):\n",
    "    with Image.open(file) as crop:\n",
    "        crop_rotated_resized_np = ImageOps.pad(\n",
    "            crop,\n",
    "            image_size, BICUBIC\n",
    "        )\n",
    "        frame = np.array(crop_rotated_resized_np).copy()\n",
    "        image_np = np.expand_dims(crop_rotated_resized_np, 0)\n",
    "        predicted_hands = sm_model.predict(\n",
    "            image_np\n",
    "        )[0]\n",
    "        predicted_hands = (predicted_hands > 0.1)\n",
    "        predicted_hands = (predicted_hands * 255).astype('uint8').squeeze()\n",
    "\n",
    "\n",
    "        predicted_kp = kp_model.predict(\n",
    "            image_np\n",
    "        )[0]\n",
    "\n",
    "        scale_x = crop_rotated_resized_np.width / predicted.shape[0]\n",
    "        scale_y = crop_rotated_resized_np.height / predicted.shape[1]\n",
    "\n",
    "        outputs = convert_mask_outputs_to_keypoints(predicted_kp,\n",
    "                                                    decode_hands_from_lines=True)\n",
    "\n",
    "\n",
    "        center = outputs[0]\n",
    "        hands_points =  extract_points_from_predictions(predicted_hands, center=center)\n",
    "\n",
    "        crop_keypoints = [\n",
    "         outputs[0],\n",
    "            outputs[1],\n",
    "            *hands_points,\n",
    "        ]\n",
    "        if len(hands_points) == 2:\n",
    "            line_proposals = [\n",
    "                Line(center, hands_points[0]),\n",
    "                Line(center, hands_points[1]),\n",
    "\n",
    "            ]\n",
    "        else:\n",
    "            line_proposals = []\n",
    "\n",
    "        zeros = np.zeros_like(predicted_hands)\n",
    "        predicted_all = np.stack((predicted_hands, zeros, zeros), axis=-1)\n",
    "        predicted_frame = cv2.cvtColor(predicted_all, cv2.COLOR_RGB2BGR)\n",
    "        for kp in crop_keypoints:\n",
    "            predicted_frame = plot_kp_on_image(predicted_frame, kp)\n",
    "\n",
    "        for line in line_proposals:\n",
    "            predicted_frame = plot_line_on_image(predicted_frame, line)\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        overlay = cv2.addWeighted(frame, 0.45, predicted_frame, 0.55, 0)\n",
    "        out.write(overlay)\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-watch-metal)",
   "language": "python",
   "name": "tf-watch-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
