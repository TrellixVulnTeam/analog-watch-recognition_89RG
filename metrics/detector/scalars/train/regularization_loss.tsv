timestamp	step	train/regularization_loss
1663411897831	0	0.0
1663411930658	1	0.0
1663411963456	2	0.0
1663411994823	3	0.0
1663412026146	4	0.0
1663412057440	5	0.0
1663412089956	6	0.0
1663412122533	7	0.0
1663412155010	8	0.0
1663412187382	9	0.0
1663412220461	10	0.0
1663412253282	11	0.0
1663412285718	12	0.0
1663412320428	13	0.0
1663412354100	14	0.0
1663412388915	15	0.0
1663412423989	16	0.0
1663412456923	17	0.0
1663412488731	18	0.0
1663412522195	19	0.0
1663412557530	20	0.0
1663412591356	21	0.0
1663412626549	22	0.0
1663412659962	23	0.0
1663412695044	24	0.0
1663412729757	25	0.0
1663412764777	26	0.0
1663412800418	27	0.0
1663412833459	28	0.0
1663412866334	29	0.0
1663412900186	30	0.0
1663412934628	31	0.0
1663412969139	32	0.0
1663413004449	33	0.0
1663413037484	34	0.0
1663413072065	35	0.0
1663413106153	36	0.0
1663413140936	37	0.0
1663413175337	38	0.0
1663413210062	39	0.0
1663413243895	40	0.0
1663413280170	41	0.0
1663413316486	42	0.0
1663413351278	43	0.0
1663413386436	44	0.0
1663413421028	45	0.0
1663413456274	46	0.0
1663413488996	47	0.0
1663413523772	48	0.0
1663413556426	49	0.0
1663413589352	50	0.0
1663413621846	51	0.0
1663413654557	52	0.0
1663413689753	53	0.0
1663413721938	54	0.0
1663413754869	55	0.0
1663413787388	56	0.0
1663413820431	57	0.0
1663413853059	58	0.0
1663413887358	59	0.0
